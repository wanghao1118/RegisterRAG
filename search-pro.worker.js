const V=Object.entries,et=Object.fromEntries,st="ENTRIES",L="KEYS",T="VALUES",_="";class D{set;_type;_path;constructor(t,s){const n=t._tree,o=Array.from(n.keys());this.set=t,this._type=s,this._path=o.length>0?[{node:n,keys:o}]:[]}next(){const t=this.dive();return this.backtrack(),t}dive(){if(this._path.length===0)return{done:!0,value:void 0};const{node:t,keys:s}=E(this._path);if(E(s)===_)return{done:!1,value:this.result()};const n=t.get(E(s));return this._path.push({node:n,keys:Array.from(n.keys())}),this.dive()}backtrack(){if(this._path.length===0)return;const t=E(this._path).keys;t.pop(),!(t.length>0)&&(this._path.pop(),this.backtrack())}key(){return this.set._prefix+this._path.map(({keys:t})=>E(t)).filter(t=>t!==_).join("")}value(){return E(this._path).node.get(_)}result(){switch(this._type){case T:return this.value();case L:return this.key();default:return[this.key(),this.value()]}}[Symbol.iterator](){return this}}const E=e=>e[e.length-1],nt=(e,t,s)=>{const n=new Map;if(t===void 0)return n;const o=t.length+1,u=o+s,i=new Uint8Array(u*o).fill(s+1);for(let r=0;r<o;++r)i[r]=r;for(let r=1;r<u;++r)i[r*o]=r;return R(e,t,s,n,i,1,o,""),n},R=(e,t,s,n,o,u,i,r)=>{const d=u*i;t:for(const c of e.keys())if(c===_){const a=o[d-1];a<=s&&n.set(r,[e.get(c),a])}else{let a=u;for(let h=0;h<c.length;++h,++a){const g=c[h],m=i*a,p=m-i;let l=o[m];const f=Math.max(0,a-s-1),y=Math.min(i-1,a+s);for(let F=f;F<y;++F){const v=g!==t[F],z=o[p+F]+ +v,A=o[p+F+1]+1,w=o[m+F]+1,j=o[m+F+1]=Math.min(z,A,w);j<l&&(l=j)}if(l>s)continue t}R(e.get(c),t,s,n,o,a,i,r+c)}};class C{_tree;_prefix;_size=void 0;constructor(t=new Map,s=""){this._tree=t,this._prefix=s}atPrefix(t){if(!t.startsWith(this._prefix))throw new Error("Mismatched prefix");const[s,n]=x(this._tree,t.slice(this._prefix.length));if(s===void 0){const[o,u]=O(n);for(const i of o.keys())if(i!==_&&i.startsWith(u)){const r=new Map;return r.set(i.slice(u.length),o.get(i)),new C(r,t)}}return new C(s,t)}clear(){this._size=void 0,this._tree.clear()}delete(t){return this._size=void 0,ot(this._tree,t)}entries(){return new D(this,st)}forEach(t){for(const[s,n]of this)t(s,n,this)}fuzzyGet(t,s){return nt(this._tree,t,s)}get(t){const s=k(this._tree,t);return s!==void 0?s.get(_):void 0}has(t){const s=k(this._tree,t);return s!==void 0&&s.has(_)}keys(){return new D(this,L)}set(t,s){if(typeof t!="string")throw new Error("key must be a string");return this._size=void 0,I(this._tree,t).set(_,s),this}get size(){if(this._size)return this._size;this._size=0;const t=this.entries();for(;!t.next().done;)this._size+=1;return this._size}update(t,s){if(typeof t!="string")throw new Error("key must be a string");this._size=void 0;const n=I(this._tree,t);return n.set(_,s(n.get(_))),this}fetch(t,s){if(typeof t!="string")throw new Error("key must be a string");this._size=void 0;const n=I(this._tree,t);let o=n.get(_);return o===void 0&&n.set(_,o=s()),o}values(){return new D(this,T)}[Symbol.iterator](){return this.entries()}static from(t){const s=new C;for(const[n,o]of t)s.set(n,o);return s}static fromObject(t){return C.from(Object.entries(t))}}const x=(e,t,s=[])=>{if(t.length===0||e==null)return[e,s];for(const n of e.keys())if(n!==_&&t.startsWith(n))return s.push([e,n]),x(e.get(n),t.slice(n.length),s);return s.push([e,t]),x(void 0,"",s)},k=(e,t)=>{if(t.length===0||e==null)return e;for(const s of e.keys())if(s!==_&&t.startsWith(s))return k(e.get(s),t.slice(s.length))},I=(e,t)=>{const s=t.length;t:for(let n=0;e&&n<s;){for(const u of e.keys())if(u!==_&&t[n]===u[0]){const i=Math.min(s-n,u.length);let r=1;for(;r<i&&t[n+r]===u[r];)++r;const d=e.get(u);if(r===u.length)e=d;else{const c=new Map;c.set(u.slice(r),d),e.set(t.slice(n,n+r),c),e.delete(u),e=c}n+=r;continue t}const o=new Map;return e.set(t.slice(n),o),o}return e},ot=(e,t)=>{const[s,n]=x(e,t);if(s!==void 0){if(s.delete(_),s.size===0)W(n);else if(s.size===1){const[o,u]=s.entries().next().value;q(n,o,u)}}},W=e=>{if(e.length===0)return;const[t,s]=O(e);if(t.delete(s),t.size===0)W(e.slice(0,-1));else if(t.size===1){const[n,o]=t.entries().next().value;n!==_&&q(e.slice(0,-1),n,o)}},q=(e,t,s)=>{if(e.length===0)return;const[n,o]=O(e);n.set(o+t,s),n.delete(o)},O=e=>e[e.length-1],ut=(e,t)=>{const s=e._idToShortId.get(t);if(s!=null)return e._storedFields.get(s)},it=/[\n\r -#%-*,-/:;?@[-\]_{}\u00A0\u00A1\u00A7\u00AB\u00B6\u00B7\u00BB\u00BF\u037E\u0387\u055A-\u055F\u0589\u058A\u05BE\u05C0\u05C3\u05C6\u05F3\u05F4\u0609\u060A\u060C\u060D\u061B\u061E\u061F\u066A-\u066D\u06D4\u0700-\u070D\u07F7-\u07F9\u0830-\u083E\u085E\u0964\u0965\u0970\u09FD\u0A76\u0AF0\u0C77\u0C84\u0DF4\u0E4F\u0E5A\u0E5B\u0F04-\u0F12\u0F14\u0F3A-\u0F3D\u0F85\u0FD0-\u0FD4\u0FD9\u0FDA\u104A-\u104F\u10FB\u1360-\u1368\u1400\u166E\u1680\u169B\u169C\u16EB-\u16ED\u1735\u1736\u17D4-\u17D6\u17D8-\u17DA\u1800-\u180A\u1944\u1945\u1A1E\u1A1F\u1AA0-\u1AA6\u1AA8-\u1AAD\u1B5A-\u1B60\u1BFC-\u1BFF\u1C3B-\u1C3F\u1C7E\u1C7F\u1CC0-\u1CC7\u1CD3\u2000-\u200A\u2010-\u2029\u202F-\u2043\u2045-\u2051\u2053-\u205F\u207D\u207E\u208D\u208E\u2308-\u230B\u2329\u232A\u2768-\u2775\u27C5\u27C6\u27E6-\u27EF\u2983-\u2998\u29D8-\u29DB\u29FC\u29FD\u2CF9-\u2CFC\u2CFE\u2CFF\u2D70\u2E00-\u2E2E\u2E30-\u2E4F\u3000-\u3003\u3008-\u3011\u3014-\u301F\u3030\u303D\u30A0\u30FB\uA4FE\uA4FF\uA60D-\uA60F\uA673\uA67E\uA6F2-\uA6F7\uA874-\uA877\uA8CE\uA8CF\uA8F8-\uA8FA\uA8FC\uA92E\uA92F\uA95F\uA9C1-\uA9CD\uA9DE\uA9DF\uAA5C-\uAA5F\uAADE\uAADF\uAAF0\uAAF1\uABEB\uFD3E\uFD3F\uFE10-\uFE19\uFE30-\uFE52\uFE54-\uFE61\uFE63\uFE68\uFE6A\uFE6B\uFF01-\uFF03\uFF05-\uFF0A\uFF0C-\uFF0F\uFF1A\uFF1B\uFF1F\uFF20\uFF3B-\uFF3D\uFF3F\uFF5B\uFF5D\uFF5F-\uFF65]+/u,M="or",$="and",rt="and_not",ct=(e,t)=>{e.includes(t)||e.push(t)},N=(e,t)=>{for(const s of t)e.includes(s)||e.push(s)},P=({score:e},{score:t})=>t-e,lt=()=>new Map,b=e=>{const t=new Map;for(const s of Object.keys(e))t.set(parseInt(s,10),e[s]);return t},G=(e,t)=>Object.prototype.hasOwnProperty.call(e,t)?e[t]:void 0,ht={[M]:(e,t)=>{for(const s of t.keys()){const n=e.get(s);if(n==null)e.set(s,t.get(s));else{const{score:o,terms:u,match:i}=t.get(s);n.score=n.score+o,n.match=Object.assign(n.match,i),N(n.terms,u)}}return e},[$]:(e,t)=>{const s=new Map;for(const n of t.keys()){const o=e.get(n);if(o==null)continue;const{score:u,terms:i,match:r}=t.get(n);N(o.terms,i),s.set(n,{score:o.score+u,terms:o.terms,match:Object.assign(o.match,r)})}return s},[rt]:(e,t)=>{for(const s of t.keys())e.delete(s);return e}},dt=(e,t,s,n,o,u)=>{const{k:i,b:r,d}=u;return Math.log(1+(s-t+.5)/(t+.5))*(d+e*(i+1)/(e+i*(1-r+r*n/o)))},at=e=>(t,s,n)=>{const o=typeof e.fuzzy=="function"?e.fuzzy(t,s,n):e.fuzzy||!1,u=typeof e.prefix=="function"?e.prefix(t,s,n):e.prefix===!0;return{term:t,fuzzy:o,prefix:u}},H=(e,t,s,n)=>{for(const o of Object.keys(e._fieldIds))if(e._fieldIds[o]===s){e._options.logger("warn",`SlimSearch: document with ID ${e._documentIds.get(t)} has changed before removal: term "${n}" was not present in field "${o}". Removing a document after it has changed can corrupt the index!`,"version_conflict");return}},ft=(e,t,s,n)=>{if(!e._index.has(n)){H(e,s,t,n);return}const o=e._index.fetch(n,lt),u=o.get(t);u==null||u.get(s)==null?H(e,s,t,n):u.get(s)<=1?u.size<=1?o.delete(t):u.delete(s):u.set(s,u.get(s)-1),e._index.get(n).size===0&&e._index.delete(n)},gt={k:1.2,b:.7,d:.5},mt={idField:"id",extractField:(e,t)=>e[t],tokenize:e=>e.split(it),processTerm:e=>e.toLowerCase(),fields:void 0,searchOptions:void 0,storeFields:[],logger:(e,t)=>{typeof console?.[e]=="function"&&console[e](t)},autoVacuum:!0},J={combineWith:M,prefix:!1,fuzzy:!1,maxFuzzy:6,boost:{},weights:{fuzzy:.45,prefix:.375},bm25:gt},pt={combineWith:$,prefix:(e,t,s)=>t===s.length-1},Ft={batchSize:1e3,batchWait:10},U={minDirtFactor:.1,minDirtCount:20},_t={...Ft,...U},K=Symbol("*"),yt=(e,t)=>{const s=new Map,n={...e._options.searchOptions,...t};for(const[o,u]of e._documentIds){const i=n.boostDocument?n.boostDocument(u,"",e._storedFields.get(o)):1;s.set(o,{score:i,terms:[],match:{}})}return s},X=(e,t=M)=>{if(e.length===0)return new Map;const s=t.toLowerCase(),n=ht[s];if(!n)throw new Error(`Invalid combination operator: ${t}`);return e.reduce(n)||new Map},S=(e,t,s,n,o,u,i,r,d=new Map)=>{if(o==null)return d;for(const c of Object.keys(u)){const a=u[c],h=e._fieldIds[c],g=o.get(h);if(g==null)continue;let m=g.size;const p=e._avgFieldLength[h];for(const l of g.keys()){if(!e._documentIds.has(l)){ft(e,h,l,s),m-=1;continue}const f=i?i(e._documentIds.get(l),s,e._storedFields.get(l)):1;if(!f)continue;const y=g.get(l),F=e._fieldLength.get(l)[h],v=dt(y,m,e._documentCount,F,p,r),z=n*a*f*v,A=d.get(l);if(A){A.score+=z,ct(A.terms,t);const w=G(A.match,s);w?w.push(c):A.match[s]=[c]}else d.set(l,{score:z,terms:[t],match:{[s]:[c]}})}}return d},At=(e,t,s)=>{const n={...e._options.searchOptions,...s},o=(n.fields||e._options.fields).reduce((l,f)=>({...l,[f]:G(n.boost,f)||1}),{}),{boostDocument:u,weights:i,maxFuzzy:r,bm25:d}=n,{fuzzy:c,prefix:a}={...J.weights,...i},h=e._index.get(t.term),g=S(e,t.term,t.term,1,h,o,u,d);let m,p;if(t.prefix&&(m=e._index.atPrefix(t.term)),t.fuzzy){const l=t.fuzzy===!0?.2:t.fuzzy,f=l<1?Math.min(r,Math.round(t.term.length*l)):l;f&&(p=e._index.fuzzyGet(t.term,f))}if(m)for(const[l,f]of m){const y=l.length-t.term.length;if(!y)continue;p?.delete(l);const F=a*l.length/(l.length+.3*y);S(e,t.term,l,F,f,o,u,d,g)}if(p)for(const l of p.keys()){const[f,y]=p.get(l);if(!y)continue;const F=c*l.length/(l.length+y);S(e,t.term,l,F,f,o,u,d,g)}return g},Y=(e,t,s={})=>{if(t===K)return yt(e,s);if(typeof t!="string"){const a={...s,...t,queries:void 0},h=t.queries.map(g=>Y(e,g,a));return X(h,a.combineWith)}const{tokenize:n,processTerm:o,searchOptions:u}=e._options,i={tokenize:n,processTerm:o,...u,...s},{tokenize:r,processTerm:d}=i,c=r(t).flatMap(a=>d(a)).filter(a=>!!a).map(at(i)).map(a=>At(e,a,i));return X(c,i.combineWith)},Q=(e,t,s={})=>{const n=Y(e,t,s),o=[];for(const[u,{score:i,terms:r,match:d}]of n){const c=r.length||1,a={id:e._documentIds.get(u),score:i*c,terms:Object.keys(d),queryTerms:r,match:d};Object.assign(a,e._storedFields.get(u)),(s.filter==null||s.filter(a))&&o.push(a)}return t===K&&s.boostDocument==null&&e._options.searchOptions.boostDocument==null||o.sort(P),o},Ct=(e,t,s={})=>{s={...e._options.autoSuggestOptions,...s};const n=new Map;for(const{score:u,terms:i}of Q(e,t,s)){const r=i.join(" "),d=n.get(r);d!=null?(d.score+=u,d.count+=1):n.set(r,{score:u,terms:i,count:1})}const o=[];for(const[u,{score:i,terms:r,count:d}]of n)o.push({suggestion:u,terms:r,score:i/d});return o.sort(P),o};class Et{_options;_index;_documentCount;_documentIds;_idToShortId;_fieldIds;_fieldLength;_avgFieldLength;_nextId;_storedFields;_dirtCount;_currentVacuum;_enqueuedVacuum;_enqueuedVacuumConditions;constructor(t){if(t?.fields==null)throw new Error('SlimSearch: option "fields" must be provided');const s=t.autoVacuum==null||t.autoVacuum===!0?_t:t.autoVacuum;this._options={...mt,...t,autoVacuum:s,searchOptions:{...J,...t.searchOptions||{}},autoSuggestOptions:{...pt,...t.autoSuggestOptions||{}}},this._index=new C,this._documentCount=0,this._documentIds=new Map,this._idToShortId=new Map,this._fieldIds={},this._fieldLength=new Map,this._avgFieldLength=[],this._nextId=0,this._storedFields=new Map,this._dirtCount=0,this._currentVacuum=null,this._enqueuedVacuum=null,this._enqueuedVacuumConditions=U,this.addFields(this._options.fields)}get isVacuuming(){return this._currentVacuum!=null}get dirtCount(){return this._dirtCount}get dirtFactor(){return this._dirtCount/(1+this._documentCount+this._dirtCount)}get documentCount(){return this._documentCount}get termCount(){return this._index.size}toJSON(){const t=[];for(const[s,n]of this._index){const o={};for(const[u,i]of n)o[u]=Object.fromEntries(i);t.push([s,o])}return{documentCount:this._documentCount,nextId:this._nextId,documentIds:Object.fromEntries(this._documentIds),fieldIds:this._fieldIds,fieldLength:Object.fromEntries(this._fieldLength),averageFieldLength:this._avgFieldLength,storedFields:Object.fromEntries(this._storedFields),dirtCount:this._dirtCount,index:t,serializationVersion:2}}addFields(t){for(let s=0;s<t.length;s++)this._fieldIds[t[s]]=s}}const zt=({index:e,documentCount:t,nextId:s,documentIds:n,fieldIds:o,fieldLength:u,averageFieldLength:i,storedFields:r,dirtCount:d,serializationVersion:c},a)=>{if(c!==1&&c!==2)throw new Error("SlimSearch: cannot deserialize an index created with an incompatible version");const h=new Et(a);h._documentCount=t,h._nextId=s,h._documentIds=b(n),h._idToShortId=new Map,h._fieldIds=o,h._fieldLength=b(u),h._avgFieldLength=i,h._storedFields=b(r),h._dirtCount=d||0,h._index=new C;for(const[g,m]of h._documentIds)h._idToShortId.set(m,g);for(const[g,m]of e){const p=new Map;for(const l of Object.keys(m)){let f=m[l];c===1&&(f=f.ds),p.set(parseInt(l,10),b(f))}h._index.set(g,p)}return h},B=(e,t)=>{const s=e.toLowerCase(),n=t.toLowerCase(),o=[];let u=0,i=0;const r=(c,a=!1)=>{let h="";i===0?h=c.length>20?`… ${c.slice(-20)}`:c:a?h=c.length+i>100?`${c.slice(0,100-i)}… `:c:h=c.length>20?`${c.slice(0,20)} … ${c.slice(-20)}`:c,h&&o.push(h),i+=h.length,a||(o.push(["mark",t]),i+=t.length,i>=100&&o.push(" …"))};let d=s.indexOf(n,u);if(d===-1)return null;for(;d>=0;){const c=d+n.length;if(r(e.slice(u,d)),u=c,i>100)break;d=s.indexOf(n,u)}return i<100&&r(e.slice(u),!0),o},wt=(e,t)=>t.contents.reduce((s,[,n])=>s+n,0)-e.contents.reduce((s,[,n])=>s+n,0),xt=(e,t)=>Math.max(...t.contents.map(([,s])=>s))-Math.max(...e.contents.map(([,s])=>s)),Z=(e,t,s={})=>{const n={};return Q(t,e,{boost:{h:2,t:1,c:4},prefix:!0,...s}).forEach(o=>{const{id:u,terms:i,score:r}=o,d=u.includes("@"),c=u.includes("#"),[a,h]=u.split(/[#@]/),g=Number(a),m=i.sort((l,f)=>l.length-f.length).filter((l,f)=>i.slice(f+1).every(y=>!y.includes(l))),{contents:p}=n[g]??={title:"",contents:[]};if(d)p.push([{type:"customField",id:g,index:h,display:m.map(l=>o.c.map(f=>B(f,l))).flat().filter(l=>l!==null)},r]);else{const l=m.map(f=>B(o.h,f)).filter(f=>f!==null);if(l.length&&p.push([{type:c?"heading":"title",id:g,...c&&{anchor:h},display:l},r]),"t"in o)for(const f of o.t){const y=m.map(F=>B(f,F)).filter(F=>F!==null);y.length&&p.push([{type:"text",id:g,...c&&{anchor:h},display:y},r])}}}),V(n).sort(([,o],[,u])=>"max"==="total"?wt(o,u):xt(o,u)).map(([o,{title:u,contents:i}])=>{if(!u){const r=ut(t,o);r&&(u=r.h)}return{title:u,contents:i.map(([r])=>r)}})},tt=(e,t,s={})=>{const n=Ct(t,e,{fuzzy:.2,maxFuzzy:3,...s}).map(({suggestion:o})=>o);return e.includes(" ")?n:n.filter(o=>!o.includes(" "))},bt=et(V(JSON.parse("{\"/\":{\"documentCount\":32,\"nextId\":32,\"documentIds\":{\"0\":\"0\",\"1\":\"2\",\"2\":\"2#from-pip\",\"3\":\"2#from-source\",\"4\":\"2#docker\",\"5\":\"3\",\"6\":\"3#basic-configuration\",\"7\":\"3#xinference-service\",\"8\":\"3#pipeline\",\"9\":\"4\",\"10\":\"4#🌟-features\",\"11\":\"4#🚀-installation\",\"12\":\"4#🙏-acknowledgements\",\"13\":\"4#🤝-contribution\",\"14\":\"4#✉️-contact-us\",\"15\":\"5\",\"16\":\"5#basic-configuration\",\"17\":\"5#how-to-add-a-new-embedding-model\",\"18\":\"5#available-embedding-models\",\"19\":\"6\",\"20\":\"7\",\"21\":\"7#basic-configuration\",\"22\":\"7#how-to-add-a-new-store-component\",\"23\":\"7#available-store-components\",\"24\":\"9\",\"25\":\"9#basic-configuration\",\"26\":\"9#how-to-add-a-new-generation-component\",\"27\":\"9#available-generation-components\",\"28\":\"10\",\"29\":\"10#basic-configuration\",\"30\":\"10#example-configuration\",\"31\":\"20\"},\"fieldIds\":{\"h\":0,\"t\":1,\"c\":2},\"fieldLength\":{\"0\":[1],\"1\":[2,7],\"2\":[2,59],\"3\":[2,46],\"4\":[1,10],\"5\":[2,44],\"6\":[2,51],\"7\":[2,115],\"8\":[1,79],\"9\":[1,20],\"10\":[2,71],\"11\":[2,24],\"12\":[2,73],\"13\":[2,16],\"14\":[3,25],\"15\":[1,61],\"16\":[2,98],\"17\":[7,71],\"18\":[3,19],\"19\":[1,36],\"20\":[1,48],\"21\":[2,58],\"22\":[7,92],\"23\":[3,14],\"24\":[1,29],\"25\":[2,62],\"26\":[7,55],\"27\":[3,32],\"28\":[1,26],\"29\":[2,31],\"30\":[2,42],\"31\":[1,3]},\"averageFieldLength\":[2.28125,44.28125],\"storedFields\":{\"0\":{\"h\":\"\"},\"1\":{\"h\":\"Installation Guide\",\"t\":[\"Note: Onlyfrom source is available now.\"]},\"2\":{\"h\":\"From pip\",\"t\":[\"A simple way to install Register RAG is to use pip, and a virtual environment is recommended. If gpu is available, you should install pytoch with gpu support. More information can be found here.\",\"conda create -n register-rag python==3.10 conda activate register-rag pip3 install torch torchvision torchaudio # For cuda12.1 pip3 install register-rag\",\"Then, you can run the following command to check if the installation is successful.\",\"python -c \\\"import register_rag; print(register_rag.__version__)\\\"\"]},\"3\":{\"h\":\"From source\",\"t\":[\"You can also install Register RAG from source. First, clone the repository.\",\"git clone https://github.com/Charon-ops/RegisterRAG.git\\\" cd RegisterRAG\",\"Then, install the dependencies.\",\"pip install -r requirements.txt\",\"Finally, install Register RAG.\",\"pip install -e .\",\"Then, you can run the following command to check if the installation is successful.\",\"python -c \\\"import register_rag; print(register_rag.__version__)\\\"\"]},\"4\":{\"h\":\"Docker\",\"t\":[\"You can also use Docker to run Register RAG.\"]},\"5\":{\"h\":\"Quick Start\",\"t\":[\"In this part, you will learn how to build a basic Register RAG pipeline.\",\"Register RAG uses a json file to configure the whole pipeline. The configuration file is divided into several parts, including embedding, store, generation and prompt. There will be more parts in the future, such as rerank, websearch, etc.\"]},\"6\":{\"h\":\"Basic Configuration\",\"t\":[\"A basic configuration file is shown below, and we will build a simple RAG pipeline using this configuration file in this part.\",\"{ \\\"embedding\\\": { \\\"embedding_type\\\": \\\"remote\\\", \\\"embedding_model_name_or_path\\\": \\\"xinference/bge-m3\\\", \\\"embedding_remote_url\\\": \\\"http://localhost:9997\\\", \\\"embedding_model_preload\\\": true }, \\\"store\\\": { \\\"store_type\\\": \\\"local\\\", \\\"store_name\\\": \\\"chroma\\\", \\\"store_local_path\\\": \\\"/path/to/chroma\\\" }, \\\"generation\\\": { \\\"generation_type\\\": \\\"remote\\\", \\\"generation_model_name_or_path\\\": \\\"xinference/qwen2-instruct\\\", \\\"generation_remote_url\\\": \\\"http://localhost:9997\\\", \\\"generation_xinference_config\\\": { \\\"xinference_model_size\\\": \\\"1_5\\\", \\\"xinference_mdoel_quantization\\\": \\\"4-bit\\\" } } }\"]},\"7\":{\"h\":\"Xinference Service\",\"t\":[\"If you want to try Register RAG using the above configuration file, you should start the xinference service first. You can refer to the xinference documentation for more information.\",\"We will use docker as an example to start the xinference service. You can run the following command to start the xinference service:\",\"# For Chinese users, you can use the following command to pull the image from Aliyun. docker pull registry.cn-hangzhou.aliyuncs.com/xprobe_xinference/xinference:latest # Or you can pull the image from Docker Hub. docker pull xprobe/xinference:latest\",\"Then, make sure that you have installed NVIDIA driver and NVIDIA Container Toolkit. More information could be found here.\",\"Finally, you can run the following command to start the xinference service:\",\"docker run -e XINFERENCE_MODEL_SRC=modelscope -p 9997:9997 --gpus all xprobe/xinference:latest xinference-local -H 0.0.0.0 --log-level debug\",\"Note: --gpus and -H must be set, and the CUDA version on the host machine should be 12.4 or above. If you have multiple GPUs, you can use --gpus 0,1,2 to specify the GPUs you want to use. The image can only run on GPU available machines. If you want to run the image on a CPU machine, you can refer to the xinference documentation for more information.\",\"After starting the xinference service, you can visit http://localhost:9997 to check if the service is running.\"]},\"8\":{\"h\":\"Pipeline\",\"t\":[\"Then, you can create a python file to run the following code:\",\"import asyncio from register_rag import Pipeline from register_rag.documents import Document from register_rag.documents.loader import PDFLoader from register_rag.documents.splitter import CharacterSplitter async def main(): pipeline = Pipeline(\\\"path/to/your/configuration.json\\\") loader = PDFLoader(\\\"path/to/your/pdf\\\") # Split the document by '\\\\n', you can use other splitters. docs = await loader.load_and_split(splitter=CharacterSplitter()) collection_name = \\\"default\\\" await self.pipeline.add_docs(docs, collection_name) # Generate the response. query = \\\"What is the capital of China?\\\" # The query you want to ask. top_k = 5 # The number of related documents you want to retrieve. return_related_docs = True # Whether to return the related documents. response, related_docs = await pipeline.get_response( query, collection_name, top_k, return_related_docs ) print(f\\\"Response: {response}\\\") print(f\\\"Related Docs: {related_docs}\\\") asyncio.run(main())\"]},\"9\":{\"h\":\"Introduction\",\"t\":[\"Register RAG provides a simple and highly customizable way to build a RAG(Retrieval-Augmented Generation) pipeline for text generation tasks.\"]},\"10\":{\"h\":\"🌟 Features\",\"t\":[\"Highly customizable\",\"You can easily customize the RAG pipeline through the configuration file using the components we provide.\",\"It is also easy to add your own components to the pipeline. You can just inherit the base class and implement the necessary methods. Then, you should regist your component in the factory. That's it!\",\"Quick to set up\",\"A python package is provided to help you set up the RAG pipeline quickly. You can install it through pip.(Under development)\",\"A docker image is provided to help you set up the RAG pipeline quickly. You can pull it from the docker hub.(Under development)\",\"Fully supports asynchronous operations\",\"Register RAG is designed to support asynchronous operations. You can easily run multiple components in parallel.\"]},\"11\":{\"h\":\"🚀 Installation\",\"t\":[\"Note: Onlyfrom source is available now. More installation methods will be provided in the future.\",\"Please refer to the Installation Guide for detailed instructions.\"]},\"12\":{\"h\":\"🙏 Acknowledgements\",\"t\":[\"We are deeply grateful for the work done by those who came before us, which has greatly facilitated the construction of our framework. Below is a list of the open-source projects we used, in no particular order:\",\"Xinference: Streamline the operation and integration of various AI models. More details can be found here.\",\"Ollama: A platform for building and deploying LLMs. More details can be found here.\",\"VuePress: Minimalistic Vue-powered static site generator. More details can be found here.\",\"vuepress-theme-hope: A vuepress theme with tons of features. More details can be found here.\",\"chroma: An open-source embedding database. More details can be found here.\"]},\"13\":{\"h\":\"🤝 Contribution\",\"t\":[\"We welcome contributions to Register RAG! Please check out the contribution guide for more information.\"]},\"14\":{\"h\":\"✉️ Contact Us\",\"t\":[\"If you have any questions or suggestions, please feel free to contact us through email or GitHub Issues. We will get back to you as soon as possible.\"]},\"15\":{\"h\":\"Embedding\",\"t\":[\"Embedding is the most critical component of the Register RAG pipeline. It transforms the input text into a vector representation, which is essential for retrieving relevant information from the database.\",\"Register RAG offers two types of embeddings:\",\"local : This method involves loading the embedding model from the local filesystem and executing it directly on the local machine.\",\"remote : This approach entails loading the embedding model from a remote server or a Docker container.\",\"From now on, we will introduce how to use the embedding component in Register RAG.\"]},\"16\":{\"h\":\"Basic Configuration\",\"t\":[\"Below is the configuration for the embedding in the Python code:\",\"class EmbeddingConfig(BaseModel): embedding_type: Literal[\\\"local\\\", \\\"remote\\\"] embedding_model_name_or_path: Optional[str] = None embedding_model_device: str = \\\"cpu\\\" embedding_model_preload: bool = False embedding_remote_url: Optional[str] = None embedding_remote_token: Optional[str] = None\",\"embedding_type: Specifies whether the embedding is local or remote.\",\"embedding_model_name_or_path: The name or path of the embedding model. For remote types, this should be accessible from the remote server.\",\"embedding_model_device: Specifies the device (CPU or CUDA) on which the model runs. For multiple GPUs, specify the GPU ID (e.g., cuda:0).\",\"embedding_model_preload: Determines whether to preload the model at program start. This setting is only valid for local embedding.\",\"embedding_remote_url: The URL for the remote server, applicable only to remote embedding.\",\"embedding_remote_token: An optional token for accessing the remote server, applicable only to remote embedding.\",\"In the configuration file (JSON format), the embedding settings are defined as follows:\",\"{ \\\"embedding\\\": { \\\"embedding_type\\\": \\\"remote\\\", \\\"embedding_model_name_or_path\\\": \\\"xinference/bge-m3\\\", \\\"embedding_remote_url\\\": \\\"http://localhost:9997\\\", \\\"embedding_model_preload\\\": true } }\",\"The embedding_model_name_or_path is divided into two parts by /: the class name of the embedding model and the model name. The class name locates the corresponding class in the code, and the model name is used to load the model.\"]},\"17\":{\"h\":\"How to add a new embedding model\",\"t\":[\"To integrate a new embedding model, inherit from the EmbeddingGetter class in register_rag.embedding. Alternatively, you can inherit directly from LocalEmbeddingGetter or RemoteEmbeddingGetter and implement the embedding method. If pre-processing or post-processing is needed, implement the pre_embedding or post_embedding methods. Pass any required parameters through the get_embedding method:\",\"async def get_embedding( self, docs: List[Document], pre_args: Dict[str, Any] = None, after_args: Dict[str, Any] = None, ) -> List[List[float]]:\",\"Example of calling get_embedding with parameters:\",\"embedding = await embedding_getter.get_embedding( docs, pre_args={\\\"pre_args\\\": \\\"value\\\"}, after_args={\\\"after_args\\\": \\\"value\\\"}, )\",\"Note: The pre_embedding and post_embedding methods return None. The get_embedding method does not utilize the return values of these methods. If returning values is required, override the get_embedding method.\"]},\"18\":{\"h\":\"Available Embedding Models\",\"t\":[\"local: \",\"BertEmbeddingGetter: The config should be like bert/model_name_or_path.\",\"SentenceTransformerEmbeddingGetter: The config should be like sentence_transformer/model_name_or_path.\",\"remote: \",\"XinferenceEmbeddingGetter: The config should be like xinference/model_name_or_path.\"]},\"19\":{\"h\":\"Guide\",\"t\":[\"In this section, we will introduce how to build your own RAG pipeline using Register RAG.\",\"You can easily customize the pipeline using the components we provide. It is also easy to add your own components to the pipeline.\",\"For more detailed information, please refer to the API documentation.\"]},\"20\":{\"h\":\"Store\",\"t\":[\"Store is designed to store documents and embeddings in a database. When the query embedding is generated, it is compared with the embeddings stored in the database to retrieve the most similar document(s).\",\"A Store component is complex and contains multiple abstract methods. As the same as the Embedding component, it is divided into two categories:\",\"local: Store the embeddings and documents directly in local disk.\",\"remote: Store the embeddings and documents in a remote database or a Docker container.\"]},\"21\":{\"h\":\"Basic Configuration\",\"t\":[\"Below is the configuration for the Store component in Python:\",\"class StoreConfig(BaseModel): store_type: Literal[\\\"local\\\", \\\"remote\\\"] store_name: Optional[str] = None store_remote_url: Optional[str] = None store_remote_token: Optional[str] = None store_local_path: Optional[str] = None\",\"store_type: The type of the Store component. It can be either local or remote.\",\"store_name: The name of the Store component.\",\"store_remote_url: The URL of the remote database. It is only required when store_type is remote.\",\"store_remote_token: The token of the remote database. It is only required when store_type is remote and the database requires a token.\",\"store_local_path: The path to the local directory where the embeddings and documents are stored. It is only required when store_type is local.\",\"In the configuration file(JSON format), the Store settings are defined as follows:\",\"{ \\\"store\\\": { \\\"store_type\\\": \\\"local\\\", \\\"store_name\\\": \\\"chroma\\\", \\\"store_local_path\\\": \\\"/path/to/data\\\" } }\"]},\"22\":{\"h\":\"How to add a new Store component\",\"t\":[\"To integrate a new Store component, you need to create a new class that inherits from the Store class and implements the abstract methods. The abstract methods are as follows:\",\"add_document: Add a single document and its embedding to the database.\",\" async def add_document( self, document: Document, embedding: List[float], collection_name: str, id: str = None, ) -> None:\",\"The add_documents method calls the add_document method in a loop by default. You can override this method to improve the performance.\",\"search_by_embedding: Retrieve the most similar document(s) based on the query embedding.\",\"async def search_by_embedding( self, embedding: List[float], collection_name: str, top_k: int = 5 ) -> List[Document]:\",\"search_by_embeddings method is not provided by default. If you need to search for multiple embeddings at once, you can add this method.\",\"get_id_by_document: Retrieve the ID of a document based on the document content.\",\"async def get_id_by_document( self, document: Document, collection_name: str ) -> str:\",\"get_ids_by_documents method calls the get_id_by_document method in a loop by default. You can override this method to improve the performance.\",\"delete_by_id: Delete a document and its embedding from the database based on the document ID.\",\"async def delete_by_id( self, id: str, collection_name: str ) -> None:\",\"delete_by_ids method calls the delete_by_id method in a loop by default. You can override this method to improve the performance.\",\"After implementing the abstract methods, you need to register the new Store component in the StoreFactory class. The StoreFactory class is responsible for creating the Store component based on the configuration.\"]},\"23\":{\"h\":\"Available Store components\",\"t\":[\"local\",\"ChromaStore : The name should be set to chroma in the configuration file.\"]},\"24\":{\"h\":\"Introduction\",\"t\":[\"The Generation component is responsible for generating responses to user queries. The prompt should be generated from a PromptGenerator, and the response should be generated from a ResponseGenerator. The Generation component is a Generator that generates responses based on the prompt generated by the PromptGenerator.\"]},\"25\":{\"h\":\"Basic Configuration\",\"t\":[\"Below is the configuration for the Generation component in Python:\",\"class GenerationConfig(BaseModel): generation_type: Literal[\\\"local\\\", \\\"remote\\\"] generation_model_name_or_path: Optional[str] = None generation_model_preload: bool = False generation_model_device: str = \\\"cpu\\\" generation_remote_url: Optional[str] = None generation_remote_token: Optional[str] = None generation_xinference_config: Optional[XinferenceConfig] = None\",\"generation_type: The type of the Generation component. It can be either local or remote.\",\"generation_model_name_or_path: The name or path of the model used for generation.\",\"generation_model_preload: Whether to load the model even if it is not called.\",\"generation_model_device: The device used for generation. It can be either cpu or cuda.\",\"generation_remote_url: The URL of the remote generation service. It is only required when generation_type is remote.\",\"generation_remote_token: The token of the remote generation service. It is only required when generation_type is remote and the service requires a token.\",\"generation_xinference_config: The configuration for the Xinference service. It is only required when generation_type is remote, and uses the Xinference service.\"]},\"26\":{\"h\":\"How to add a new Generation component\",\"t\":[\"To integrate a new Generation component, you need to create a new class that inherits from the Generator class and implements the abstract methods, or you can inherits from the LocalGenerator or RemoteGenerator. The abstract methods are as follows:\",\"generate: Generate the response with user prompt, system prompt and history messages.\",\" async def generate( self, prompt: str, history: List[ResponseMessage] = None, system_prompt: str = None, ) -> str:\",\"The ResponseMessage is defined as below:\",\"class ResponseMessage(TypedDict): content: str role: Literal[\\\"system\\\", \\\"user\\\", \\\"assistant\\\"]\"]},\"27\":{\"h\":\"Available Generation components\",\"t\":[\"local: \",\"TransformersGenerator: A generator that uses the Transformers library for local generation. The model_name_or_path should be configured like transformers/xxx.\",\"remote: \",\"OllamaGenerator: A generator that calls the Ollama service for generation. The model_name_or_path should be configured like ollama/xxx.\",\"XinfernceGenerator: A generator that calls the Xinference service for generation. The model_name_or_path should be configured like xinference/xxx.\"]},\"28\":{\"h\":\"Xinference\",\"t\":[\"Xorbits Inference (Xinference) is an open-source platform to streamline the operation and integration of a wide array of AI models. For more information, see the Xinference Documentation.\"]},\"29\":{\"h\":\"Basic Configuration\",\"t\":[\"Below is the configuration for the Xinference service in Python:\",\"class XinferenceConfig(BaseModel): xinference_model_engine: str = \\\"Transformers\\\" xinference_model_format: str = \\\"pytorch\\\" xinference_ngpu: str = \\\"auto\\\" xinference_model_size: str xinference_mdoel_quantization: str\",\"xinference_model_engine: The engine used for the model.\",\"xinference_model_format: The format of the model.\",\"xinference_ngpu: The number of GPUs used for the model.\",\"xinference_model_size: The size of the model.\",\"xinference_mdoel_quantization: The quantization of the model.\"]},\"30\":{\"h\":\"Example Configuration\",\"t\":[\"{ \\\"generation\\\": { \\\"generation_type\\\": \\\"remote\\\", \\\"generation_model_name_or_path\\\": \\\"xinference/qwen2-instruct\\\", \\\"generation_remote_url\\\": \\\"http://localhost:9997\\\", \\\"generation_xinference_config\\\": { \\\"xinference_model_size\\\": \\\"1_5\\\", \\\"xinference_mdoel_quantization\\\": \\\"4-bit\\\" } } }\",\"Note: The model name is set to xinference/qwen2-instruct. The xinferece prefix is used to indicate that the model is hosted on the Xinference service, and qwen2-instruct is the name of the model. A / is used to separate the service name and the model name.\"]},\"31\":{\"h\":\"\",\"t\":[\"404 Not Found\"]}},\"dirtCount\":0,\"index\":[[\">\",{\"1\":{\"17\":1,\"22\":4,\"26\":1}}],[\"✉️\",{\"0\":{\"14\":1}}],[\"🤝\",{\"0\":{\"13\":1}}],[\"🙏\",{\"0\":{\"12\":1}}],[\"🚀\",{\"0\":{\"11\":1}}],[\"just\",{\"1\":{\"10\":1}}],[\"json\",{\"1\":{\"5\":1,\"8\":1,\"16\":1,\"21\":1}}],[\"🌟\",{\"0\":{\"10\":1}}],[\"k\",{\"1\":{\"8\":2,\"22\":1}}],[\"=\",{\"1\":{\"8\":8,\"16\":5,\"17\":3,\"21\":4,\"22\":2,\"25\":6,\"26\":2,\"29\":3}}],[\"2\",{\"1\":{\"7\":1}}],[\"0\",{\"1\":{\"7\":5,\"16\":1}}],[\"xorbits\",{\"1\":{\"28\":1}}],[\"xinferece\",{\"1\":{\"30\":1}}],[\"xinferenceconfig\",{\"1\":{\"25\":1,\"29\":1}}],[\"xinferenceembeddinggetter\",{\"1\":{\"18\":1}}],[\"xinference\",{\"0\":{\"7\":1,\"28\":1},\"1\":{\"6\":5,\"7\":13,\"12\":1,\"16\":1,\"18\":1,\"25\":4,\"27\":2,\"28\":2,\"29\":11,\"30\":6}}],[\"xinferncegenerator\",{\"1\":{\"27\":1}}],[\"xxx\",{\"1\":{\"27\":3}}],[\"xprobe\",{\"1\":{\"7\":3}}],[\"404\",{\"1\":{\"31\":1}}],[\"4\",{\"1\":{\"6\":1,\"7\":1,\"30\":1}}],[\"5\",{\"1\":{\"6\":1,\"8\":1,\"22\":1,\"30\":1}}],[\"queries\",{\"1\":{\"24\":1}}],[\"query\",{\"1\":{\"8\":3,\"20\":1,\"22\":1}}],[\"questions\",{\"1\":{\"14\":1}}],[\"quantization\",{\"1\":{\"6\":1,\"29\":3,\"30\":1}}],[\"quickly\",{\"1\":{\"10\":2}}],[\"quick\",{\"0\":{\"5\":1},\"1\":{\"10\":1}}],[\"qwen2\",{\"1\":{\"6\":1,\"30\":3}}],[\"9997\",{\"1\":{\"6\":2,\"7\":3,\"16\":1,\"30\":1}}],[\"library\",{\"1\":{\"27\":1}}],[\"like\",{\"1\":{\"18\":3,\"27\":3}}],[\"literal\",{\"1\":{\"16\":1,\"21\":1,\"25\":1,\"26\":1}}],[\"list\",{\"1\":{\"12\":1,\"17\":3,\"22\":3,\"26\":1}}],[\"llms\",{\"1\":{\"12\":1}}],[\"level\",{\"1\":{\"7\":1}}],[\"learn\",{\"1\":{\"5\":1}}],[\"loop\",{\"1\":{\"22\":3}}],[\"locates\",{\"1\":{\"16\":1}}],[\"localgenerator\",{\"1\":{\"26\":1}}],[\"localembeddinggetter\",{\"1\":{\"17\":1}}],[\"local\",{\"1\":{\"6\":2,\"7\":1,\"15\":3,\"16\":3,\"18\":1,\"20\":2,\"21\":8,\"23\":1,\"25\":2,\"27\":2}}],[\"localhost\",{\"1\":{\"6\":2,\"7\":1,\"16\":1,\"30\":1}}],[\"loading\",{\"1\":{\"15\":2}}],[\"load\",{\"1\":{\"8\":1,\"16\":1,\"25\":1}}],[\"loader\",{\"1\":{\"8\":3}}],[\"log\",{\"1\":{\"7\":1}}],[\"latest\",{\"1\":{\"7\":3}}],[\"utilize\",{\"1\":{\"17\":1}}],[\"under\",{\"1\":{\"10\":2}}],[\"up\",{\"1\":{\"10\":3}}],[\"url\",{\"1\":{\"6\":2,\"16\":4,\"21\":3,\"25\":3,\"30\":1}}],[\"us\",{\"0\":{\"14\":1},\"1\":{\"12\":1,\"14\":1}}],[\"using\",{\"1\":{\"6\":1,\"7\":1,\"10\":1,\"19\":2}}],[\"user\",{\"1\":{\"24\":1,\"26\":2}}],[\"users\",{\"1\":{\"7\":1}}],[\"used\",{\"1\":{\"12\":1,\"16\":1,\"25\":2,\"29\":2,\"30\":2}}],[\"uses\",{\"1\":{\"5\":1,\"25\":1,\"27\":1}}],[\"use\",{\"1\":{\"2\":1,\"4\":1,\"7\":4,\"8\":1,\"15\":1}}],[\"messages\",{\"1\":{\"26\":1}}],[\"method\",{\"1\":{\"15\":1,\"17\":4,\"22\":11}}],[\"methods\",{\"1\":{\"10\":1,\"11\":1,\"17\":3,\"20\":1,\"22\":3,\"26\":2}}],[\"minimalistic\",{\"1\":{\"12\":1}}],[\"multiple\",{\"1\":{\"7\":1,\"10\":1,\"16\":1,\"20\":1,\"22\":1}}],[\"must\",{\"1\":{\"7\":1}}],[\"main\",{\"1\":{\"8\":2}}],[\"machines\",{\"1\":{\"7\":1}}],[\"machine\",{\"1\":{\"7\":2,\"15\":1}}],[\"make\",{\"1\":{\"7\":1}}],[\"mdoel\",{\"1\":{\"6\":1,\"29\":2,\"30\":1}}],[\"m3\",{\"1\":{\"6\":1,\"16\":1}}],[\"most\",{\"1\":{\"15\":1,\"20\":1,\"22\":1}}],[\"models\",{\"0\":{\"18\":1},\"1\":{\"12\":1,\"28\":1}}],[\"model\",{\"0\":{\"17\":1},\"1\":{\"6\":4,\"7\":1,\"15\":2,\"16\":16,\"17\":1,\"18\":3,\"25\":8,\"27\":3,\"29\":11,\"30\":6}}],[\"more\",{\"1\":{\"2\":1,\"5\":1,\"7\":3,\"11\":1,\"12\":5,\"13\":1,\"19\":1,\"28\":1}}],[\"bool\",{\"1\":{\"16\":1,\"25\":1}}],[\"back\",{\"1\":{\"14\":1}}],[\"based\",{\"1\":{\"22\":4,\"24\":1}}],[\"basemodel\",{\"1\":{\"16\":1,\"21\":1,\"25\":1,\"29\":1}}],[\"base\",{\"1\":{\"10\":1}}],[\"basic\",{\"0\":{\"6\":1,\"16\":1,\"21\":1,\"25\":1,\"29\":1},\"1\":{\"5\":1,\"6\":1}}],[\"by\",{\"1\":{\"8\":1,\"12\":1,\"16\":1,\"22\":15,\"24\":1}}],[\"bit\",{\"1\":{\"6\":1,\"30\":1}}],[\"bge\",{\"1\":{\"6\":1,\"16\":1}}],[\"building\",{\"1\":{\"12\":1}}],[\"build\",{\"1\":{\"5\":1,\"6\":1,\"9\":1,\"19\":1}}],[\"bert\",{\"1\":{\"18\":1}}],[\"bertembeddinggetter\",{\"1\":{\"18\":1}}],[\"before\",{\"1\":{\"12\":1}}],[\"below\",{\"1\":{\"6\":1,\"12\":1,\"16\":1,\"21\":1,\"25\":1,\"26\":1,\"29\":1}}],[\"be\",{\"1\":{\"2\":1,\"5\":1,\"7\":3,\"11\":1,\"12\":5,\"16\":1,\"18\":3,\"21\":1,\"23\":1,\"24\":2,\"25\":2,\"27\":3}}],[\"data\",{\"1\":{\"21\":1}}],[\"database\",{\"1\":{\"12\":1,\"15\":1,\"20\":3,\"21\":3,\"22\":2}}],[\"directory\",{\"1\":{\"21\":1}}],[\"directly\",{\"1\":{\"15\":1,\"17\":1,\"20\":1}}],[\"disk\",{\"1\":{\"20\":1}}],[\"dict\",{\"1\":{\"17\":2}}],[\"divided\",{\"1\":{\"5\":1,\"16\":1,\"20\":1}}],[\"does\",{\"1\":{\"17\":1}}],[\"done\",{\"1\":{\"12\":1}}],[\"docs\",{\"1\":{\"8\":8,\"17\":2}}],[\"document\",{\"1\":{\"8\":2,\"17\":1,\"20\":1,\"22\":17}}],[\"documents\",{\"1\":{\"8\":5,\"20\":3,\"21\":1,\"22\":2}}],[\"documentation\",{\"1\":{\"7\":2,\"19\":1,\"28\":1}}],[\"docker\",{\"0\":{\"4\":1},\"1\":{\"4\":1,\"7\":5,\"10\":2,\"15\":1,\"20\":1}}],[\"delete\",{\"1\":{\"22\":5}}],[\"determines\",{\"1\":{\"16\":1}}],[\"details\",{\"1\":{\"12\":5}}],[\"detailed\",{\"1\":{\"11\":1,\"19\":1}}],[\"device\",{\"1\":{\"16\":3,\"25\":3}}],[\"development\",{\"1\":{\"10\":2}}],[\"deploying\",{\"1\":{\"12\":1}}],[\"dependencies\",{\"1\":{\"3\":1}}],[\"deeply\",{\"1\":{\"12\":1}}],[\"designed\",{\"1\":{\"10\":1,\"20\":1}}],[\"defined\",{\"1\":{\"16\":1,\"21\":1,\"26\":1}}],[\"default\",{\"1\":{\"8\":1,\"22\":4}}],[\"def\",{\"1\":{\"8\":1,\"17\":1,\"22\":4,\"26\":1}}],[\"debug\",{\"1\":{\"7\":1}}],[\"driver\",{\"1\":{\"7\":1}}],[\"even\",{\"1\":{\"25\":1}}],[\"either\",{\"1\":{\"21\":1,\"25\":2}}],[\"engine\",{\"1\":{\"29\":3}}],[\"entails\",{\"1\":{\"15\":1}}],[\"environment\",{\"1\":{\"2\":1}}],[\"executing\",{\"1\":{\"15\":1}}],[\"example\",{\"0\":{\"30\":1},\"1\":{\"7\":1,\"17\":1}}],[\"essential\",{\"1\":{\"15\":1}}],[\"email\",{\"1\":{\"14\":1}}],[\"embeddinggetter\",{\"1\":{\"17\":1}}],[\"embeddingconfig\",{\"1\":{\"16\":1}}],[\"embeddings\",{\"1\":{\"15\":1,\"20\":4,\"21\":1,\"22\":2}}],[\"embedding\",{\"0\":{\"15\":1,\"17\":1,\"18\":1},\"1\":{\"5\":1,\"6\":5,\"12\":1,\"15\":4,\"16\":26,\"17\":15,\"20\":2,\"22\":7}}],[\"easy\",{\"1\":{\"10\":1,\"19\":1}}],[\"easily\",{\"1\":{\"10\":2,\"19\":1}}],[\"etc\",{\"1\":{\"5\":1}}],[\"e\",{\"1\":{\"3\":1,\"7\":1,\"16\":1}}],[\"override\",{\"1\":{\"17\":1,\"22\":3}}],[\"out\",{\"1\":{\"13\":1}}],[\"our\",{\"1\":{\"12\":1}}],[\"ollamagenerator\",{\"1\":{\"27\":1}}],[\"ollama\",{\"1\":{\"12\":1,\"27\":2}}],[\"optional\",{\"1\":{\"16\":4,\"21\":4,\"25\":4}}],[\"operation\",{\"1\":{\"12\":1,\"28\":1}}],[\"operations\",{\"1\":{\"10\":2}}],[\"open\",{\"1\":{\"12\":2,\"28\":1}}],[\"ops\",{\"1\":{\"3\":1}}],[\"own\",{\"1\":{\"10\":1,\"19\":2}}],[\"offers\",{\"1\":{\"15\":1}}],[\"of\",{\"1\":{\"8\":2,\"12\":4,\"15\":2,\"16\":2,\"17\":2,\"21\":4,\"22\":1,\"25\":4,\"28\":2,\"29\":4,\"30\":1}}],[\"other\",{\"1\":{\"8\":1}}],[\"once\",{\"1\":{\"22\":1}}],[\"only\",{\"1\":{\"7\":1,\"16\":3,\"21\":3,\"25\":3}}],[\"onlyfrom\",{\"1\":{\"1\":1,\"11\":1}}],[\"on\",{\"1\":{\"7\":3,\"15\":2,\"16\":1,\"22\":4,\"24\":1,\"30\":1}}],[\"order\",{\"1\":{\"12\":1}}],[\"or\",{\"1\":{\"6\":2,\"7\":2,\"14\":2,\"15\":1,\"16\":7,\"17\":3,\"18\":3,\"20\":1,\"21\":1,\"25\":5,\"26\":2,\"27\":3,\"30\":1}}],[\"history\",{\"1\":{\"26\":2}}],[\"highly\",{\"1\":{\"9\":1,\"10\":1}}],[\"help\",{\"1\":{\"10\":2}}],[\"here\",{\"1\":{\"2\":1,\"7\":1,\"12\":5}}],[\"hope\",{\"1\":{\"12\":1}}],[\"hosted\",{\"1\":{\"30\":1}}],[\"host\",{\"1\":{\"7\":1}}],[\"how\",{\"0\":{\"17\":1,\"22\":1,\"26\":1},\"1\":{\"5\":1,\"15\":1,\"19\":1}}],[\"h\",{\"1\":{\"7\":2}}],[\"has\",{\"1\":{\"12\":1}}],[\"have\",{\"1\":{\"7\":2,\"14\":1}}],[\"hangzhou\",{\"1\":{\"7\":1}}],[\"hub\",{\"1\":{\"7\":1,\"10\":1}}],[\"http\",{\"1\":{\"6\":2,\"7\":1,\"16\":1,\"30\":1}}],[\"https\",{\"1\":{\"3\":1}}],[\"values\",{\"1\":{\"17\":2}}],[\"value\",{\"1\":{\"17\":2}}],[\"valid\",{\"1\":{\"16\":1}}],[\"various\",{\"1\":{\"12\":1}}],[\"vector\",{\"1\":{\"15\":1}}],[\"version\",{\"1\":{\"2\":1,\"3\":1,\"7\":1}}],[\"vue\",{\"1\":{\"12\":1}}],[\"vuepress\",{\"1\":{\"12\":3}}],[\"visit\",{\"1\":{\"7\":1}}],[\"virtual\",{\"1\":{\"2\":1}}],[\"two\",{\"1\":{\"15\":1,\"16\":1,\"20\":1}}],[\"tasks\",{\"1\":{\"9\":1}}],[\"text\",{\"1\":{\"9\":1,\"15\":1}}],[\"transformers\",{\"1\":{\"27\":2,\"29\":1}}],[\"transformersgenerator\",{\"1\":{\"27\":1}}],[\"transformer\",{\"1\":{\"18\":1}}],[\"transforms\",{\"1\":{\"15\":1}}],[\"try\",{\"1\":{\"7\":1}}],[\"true\",{\"1\":{\"6\":1,\"8\":1,\"16\":1}}],[\"typeddict\",{\"1\":{\"26\":1}}],[\"types\",{\"1\":{\"15\":1,\"16\":1}}],[\"type\",{\"1\":{\"6\":3,\"16\":3,\"21\":7,\"25\":6,\"30\":1}}],[\"those\",{\"1\":{\"12\":1}}],[\"through\",{\"1\":{\"10\":2,\"14\":1,\"17\":1}}],[\"that\",{\"1\":{\"7\":1,\"10\":1,\"22\":1,\"24\":1,\"26\":1,\"27\":3,\"30\":1}}],[\"this\",{\"1\":{\"5\":1,\"6\":2,\"15\":2,\"16\":2,\"19\":1,\"22\":4}}],[\"these\",{\"1\":{\"17\":1}}],[\"theme\",{\"1\":{\"12\":2}}],[\"there\",{\"1\":{\"5\":1}}],[\"the\",{\"1\":{\"2\":2,\"3\":4,\"5\":3,\"7\":19,\"8\":7,\"10\":10,\"11\":2,\"12\":4,\"13\":1,\"15\":9,\"16\":25,\"17\":8,\"18\":3,\"19\":4,\"20\":8,\"21\":16,\"22\":23,\"23\":2,\"24\":6,\"25\":16,\"26\":6,\"27\":6,\"28\":2,\"29\":12,\"30\":8}}],[\"then\",{\"1\":{\"2\":1,\"3\":2,\"7\":1,\"8\":1,\"10\":1}}],[\"txt\",{\"1\":{\"3\":1}}],[\"token\",{\"1\":{\"16\":3,\"21\":4,\"25\":4}}],[\"tons\",{\"1\":{\"12\":1}}],[\"top\",{\"1\":{\"8\":2,\"22\":1}}],[\"toolkit\",{\"1\":{\"7\":1}}],[\"torchaudio\",{\"1\":{\"2\":1}}],[\"torchvision\",{\"1\":{\"2\":1}}],[\"torch\",{\"1\":{\"2\":1}}],[\"to\",{\"0\":{\"17\":1,\"22\":1,\"26\":1},\"1\":{\"2\":3,\"3\":1,\"4\":1,\"5\":2,\"6\":1,\"7\":11,\"8\":6,\"9\":1,\"10\":6,\"11\":1,\"13\":1,\"14\":2,\"15\":1,\"16\":4,\"17\":1,\"19\":4,\"20\":2,\"21\":2,\"22\":8,\"23\":1,\"24\":1,\"25\":1,\"26\":2,\"28\":1,\"30\":3}}],[\"12\",{\"1\":{\"7\":1}}],[\"1\",{\"1\":{\"2\":1,\"6\":1,\"7\":1,\"30\":1}}],[\"10\",{\"1\":{\"2\":1}}],[\"ngpu\",{\"1\":{\"29\":2}}],[\"need\",{\"1\":{\"22\":3,\"26\":1}}],[\"needed\",{\"1\":{\"17\":1}}],[\"new\",{\"0\":{\"17\":1,\"22\":1,\"26\":1},\"1\":{\"17\":1,\"22\":3,\"26\":2}}],[\"necessary\",{\"1\":{\"10\":1}}],[\"number\",{\"1\":{\"8\":1,\"29\":1}}],[\"nvidia\",{\"1\":{\"7\":2}}],[\"name\",{\"1\":{\"6\":3,\"8\":3,\"16\":9,\"18\":3,\"21\":4,\"22\":4,\"23\":1,\"25\":3,\"27\":3,\"30\":5}}],[\"n\",{\"1\":{\"2\":1,\"8\":1}}],[\"not\",{\"1\":{\"17\":1,\"22\":1,\"25\":1,\"31\":1}}],[\"note\",{\"1\":{\"1\":1,\"7\":1,\"11\":1,\"17\":1,\"30\":1}}],[\"none\",{\"1\":{\"16\":3,\"17\":3,\"21\":4,\"22\":3,\"25\":4,\"26\":2}}],[\"no\",{\"1\":{\"12\":1}}],[\"now\",{\"1\":{\"1\":1,\"11\":1,\"15\":1}}],[\"creating\",{\"1\":{\"22\":1}}],[\"create\",{\"1\":{\"2\":1,\"8\":1,\"22\":1,\"26\":1}}],[\"critical\",{\"1\":{\"15\":1}}],[\"class\",{\"1\":{\"10\":1,\"16\":4,\"17\":1,\"21\":1,\"22\":4,\"25\":1,\"26\":3,\"29\":1}}],[\"clone\",{\"1\":{\"3\":2}}],[\"customize\",{\"1\":{\"10\":1,\"19\":1}}],[\"customizable\",{\"1\":{\"9\":1,\"10\":1}}],[\"cuda\",{\"1\":{\"7\":1,\"16\":2,\"25\":1}}],[\"cuda12\",{\"1\":{\"2\":1}}],[\"called\",{\"1\":{\"25\":1}}],[\"calls\",{\"1\":{\"22\":3,\"27\":2}}],[\"calling\",{\"1\":{\"17\":1}}],[\"categories\",{\"1\":{\"20\":1}}],[\"came\",{\"1\":{\"12\":1}}],[\"capital\",{\"1\":{\"8\":1}}],[\"can\",{\"1\":{\"2\":2,\"3\":2,\"4\":1,\"7\":9,\"8\":2,\"10\":5,\"12\":5,\"17\":1,\"19\":1,\"21\":1,\"22\":4,\"25\":2,\"26\":1}}],[\"cpu\",{\"1\":{\"7\":1,\"16\":2,\"25\":2}}],[\"cn\",{\"1\":{\"7\":1}}],[\"cd\",{\"1\":{\"3\":1}}],[\"china\",{\"1\":{\"8\":1}}],[\"chinese\",{\"1\":{\"7\":1}}],[\"charactersplitter\",{\"1\":{\"8\":1}}],[\"charon\",{\"1\":{\"3\":1}}],[\"chromastore\",{\"1\":{\"23\":1}}],[\"chroma\",{\"1\":{\"6\":2,\"12\":1,\"21\":1,\"23\":1}}],[\"check\",{\"1\":{\"2\":1,\"3\":1,\"7\":1,\"13\":1}}],[\"c\",{\"1\":{\"2\":1,\"3\":1}}],[\"corresponding\",{\"1\":{\"16\":1}}],[\"collection\",{\"1\":{\"8\":3,\"22\":4}}],[\"code\",{\"1\":{\"8\":1,\"16\":2}}],[\"could\",{\"1\":{\"7\":1}}],[\"content\",{\"1\":{\"22\":1,\"26\":1}}],[\"contains\",{\"1\":{\"20\":1}}],[\"container\",{\"1\":{\"7\":1,\"15\":1,\"20\":1}}],[\"contact\",{\"0\":{\"14\":1},\"1\":{\"14\":1}}],[\"contributions\",{\"1\":{\"13\":1}}],[\"contribution\",{\"0\":{\"13\":1},\"1\":{\"13\":1}}],[\"construction\",{\"1\":{\"12\":1}}],[\"config\",{\"1\":{\"6\":1,\"18\":3,\"25\":2,\"30\":1}}],[\"configuration\",{\"0\":{\"6\":1,\"16\":1,\"21\":1,\"25\":1,\"29\":1,\"30\":1},\"1\":{\"5\":1,\"6\":2,\"7\":1,\"8\":1,\"10\":1,\"16\":2,\"21\":2,\"22\":1,\"23\":1,\"25\":2,\"29\":1}}],[\"configured\",{\"1\":{\"27\":3}}],[\"configure\",{\"1\":{\"5\":1}}],[\"conda\",{\"1\":{\"2\":2}}],[\"complex\",{\"1\":{\"20\":1}}],[\"compared\",{\"1\":{\"20\":1}}],[\"component\",{\"0\":{\"22\":1,\"26\":1},\"1\":{\"10\":1,\"15\":2,\"20\":2,\"21\":3,\"22\":3,\"24\":2,\"25\":2,\"26\":1}}],[\"components\",{\"0\":{\"23\":1,\"27\":1},\"1\":{\"10\":3,\"19\":2}}],[\"com\",{\"1\":{\"3\":1,\"7\":1}}],[\"command\",{\"1\":{\"2\":1,\"3\":1,\"7\":3}}],[\"float\",{\"1\":{\"17\":1,\"22\":2}}],[\"false\",{\"1\":{\"16\":1,\"25\":1}}],[\"facilitated\",{\"1\":{\"12\":1}}],[\"factory\",{\"1\":{\"10\":1}}],[\"feel\",{\"1\":{\"14\":1}}],[\"features\",{\"0\":{\"10\":1},\"1\":{\"12\":1}}],[\"free\",{\"1\":{\"14\":1}}],[\"framework\",{\"1\":{\"12\":1}}],[\"from\",{\"0\":{\"2\":1,\"3\":1},\"1\":{\"3\":1,\"7\":2,\"8\":4,\"10\":1,\"15\":4,\"16\":1,\"17\":2,\"22\":2,\"24\":2,\"26\":2}}],[\"fully\",{\"1\":{\"10\":1}}],[\"future\",{\"1\":{\"5\":1,\"11\":1}}],[\"f\",{\"1\":{\"8\":2}}],[\"filesystem\",{\"1\":{\"15\":1}}],[\"file\",{\"1\":{\"5\":2,\"6\":2,\"7\":1,\"8\":1,\"10\":1,\"16\":1,\"21\":1,\"23\":1}}],[\"finally\",{\"1\":{\"3\":1,\"7\":1}}],[\"first\",{\"1\":{\"3\":1,\"7\":1}}],[\"follows\",{\"1\":{\"16\":1,\"21\":1,\"22\":1,\"26\":1}}],[\"following\",{\"1\":{\"2\":1,\"3\":1,\"7\":3,\"8\":1}}],[\"format\",{\"1\":{\"16\":1,\"21\":1,\"29\":3}}],[\"for\",{\"1\":{\"2\":1,\"7\":3,\"9\":1,\"11\":1,\"12\":2,\"13\":1,\"15\":1,\"16\":6,\"19\":1,\"21\":1,\"22\":2,\"24\":1,\"25\":4,\"27\":3,\"28\":1,\"29\":3}}],[\"found\",{\"1\":{\"2\":1,\"7\":1,\"12\":5,\"31\":1}}],[\"work\",{\"1\":{\"12\":1}}],[\"where\",{\"1\":{\"21\":1}}],[\"when\",{\"1\":{\"20\":1,\"21\":3,\"25\":3}}],[\"whether\",{\"1\":{\"8\":1,\"16\":2,\"25\":1}}],[\"which\",{\"1\":{\"12\":1,\"15\":1,\"16\":1}}],[\"who\",{\"1\":{\"12\":1}}],[\"whole\",{\"1\":{\"5\":1}}],[\"what\",{\"1\":{\"8\":1}}],[\"want\",{\"1\":{\"7\":3,\"8\":2}}],[\"way\",{\"1\":{\"2\":1,\"9\":1}}],[\"welcome\",{\"1\":{\"13\":1}}],[\"we\",{\"1\":{\"6\":1,\"7\":1,\"10\":1,\"12\":2,\"13\":1,\"14\":1,\"15\":1,\"19\":2}}],[\"websearch\",{\"1\":{\"5\":1}}],[\"wide\",{\"1\":{\"28\":1}}],[\"will\",{\"1\":{\"5\":2,\"6\":1,\"7\":1,\"11\":1,\"14\":1,\"15\":1,\"19\":1}}],[\"with\",{\"1\":{\"2\":1,\"12\":1,\"17\":1,\"20\":1,\"26\":1}}],[\"performance\",{\"1\":{\"22\":3}}],[\"post\",{\"1\":{\"17\":3}}],[\"possible\",{\"1\":{\"14\":1}}],[\"powered\",{\"1\":{\"12\":1}}],[\"platform\",{\"1\":{\"12\":1,\"28\":1}}],[\"please\",{\"1\":{\"11\":1,\"13\":1,\"14\":1,\"19\":1}}],[\"pdf\",{\"1\":{\"8\":1}}],[\"pdfloader\",{\"1\":{\"8\":2}}],[\"p\",{\"1\":{\"7\":1}}],[\"pull\",{\"1\":{\"7\":4,\"10\":1}}],[\"pass\",{\"1\":{\"17\":1}}],[\"parameters\",{\"1\":{\"17\":2}}],[\"parallel\",{\"1\":{\"10\":1}}],[\"particular\",{\"1\":{\"12\":1}}],[\"parts\",{\"1\":{\"5\":2,\"16\":1}}],[\"part\",{\"1\":{\"5\":1,\"6\":1}}],[\"package\",{\"1\":{\"10\":1}}],[\"path\",{\"1\":{\"6\":4,\"8\":2,\"16\":5,\"18\":3,\"21\":5,\"25\":3,\"27\":3,\"30\":1}}],[\"prefix\",{\"1\":{\"30\":1}}],[\"pre\",{\"1\":{\"17\":6}}],[\"preload\",{\"1\":{\"6\":1,\"16\":4,\"25\":2}}],[\"processing\",{\"1\":{\"17\":2}}],[\"program\",{\"1\":{\"16\":1}}],[\"projects\",{\"1\":{\"12\":1}}],[\"provided\",{\"1\":{\"10\":2,\"11\":1,\"22\":1}}],[\"provide\",{\"1\":{\"10\":1,\"19\":1}}],[\"provides\",{\"1\":{\"9\":1}}],[\"promptgenerator\",{\"1\":{\"24\":2}}],[\"prompt\",{\"1\":{\"5\":1,\"24\":2,\"26\":4}}],[\"print\",{\"1\":{\"2\":1,\"3\":1,\"8\":2}}],[\"pytorch\",{\"1\":{\"29\":1}}],[\"pytoch\",{\"1\":{\"2\":1}}],[\"python\",{\"1\":{\"2\":1,\"3\":1,\"8\":1,\"10\":1,\"16\":1,\"21\":1,\"25\":1,\"29\":1}}],[\"python==3\",{\"1\":{\"2\":1}}],[\"pipeline\",{\"0\":{\"8\":1},\"1\":{\"5\":2,\"6\":1,\"8\":5,\"9\":1,\"10\":4,\"15\":1,\"19\":3}}],[\"pip3\",{\"1\":{\"2\":2}}],[\"pip\",{\"0\":{\"2\":1},\"1\":{\"2\":1,\"3\":2,\"10\":1}}],[\"your\",{\"1\":{\"8\":2,\"10\":2,\"19\":2}}],[\"you\",{\"1\":{\"2\":2,\"3\":2,\"4\":1,\"5\":1,\"7\":14,\"8\":4,\"10\":8,\"14\":2,\"17\":1,\"19\":1,\"22\":7,\"26\":2}}],[\"g\",{\"1\":{\"16\":1}}],[\"greatly\",{\"1\":{\"12\":1}}],[\"grateful\",{\"1\":{\"12\":1}}],[\"getter\",{\"1\":{\"17\":1}}],[\"get\",{\"1\":{\"8\":1,\"14\":1,\"17\":6,\"22\":4}}],[\"generating\",{\"1\":{\"24\":1}}],[\"generationconfig\",{\"1\":{\"25\":1}}],[\"generation\",{\"0\":{\"26\":1,\"27\":1},\"1\":{\"5\":1,\"6\":5,\"9\":2,\"24\":2,\"25\":23,\"26\":1,\"27\":3,\"30\":5}}],[\"generator\",{\"1\":{\"12\":1,\"24\":1,\"26\":1,\"27\":3}}],[\"generates\",{\"1\":{\"24\":1}}],[\"generated\",{\"1\":{\"20\":1,\"24\":3}}],[\"generate\",{\"1\":{\"8\":1,\"26\":3}}],[\"github\",{\"1\":{\"3\":1,\"14\":1}}],[\"git\",{\"1\":{\"3\":2}}],[\"gpus\",{\"1\":{\"7\":5,\"16\":1,\"29\":1}}],[\"gpu\",{\"1\":{\"2\":2,\"7\":1,\"16\":1}}],[\"guide\",{\"0\":{\"1\":1,\"19\":1},\"1\":{\"11\":1,\"13\":1}}],[\"role\",{\"1\":{\"26\":1}}],[\"r\",{\"1\":{\"3\":1}}],[\"runs\",{\"1\":{\"16\":1}}],[\"running\",{\"1\":{\"7\":1}}],[\"run\",{\"1\":{\"2\":1,\"3\":1,\"4\":1,\"7\":5,\"8\":2,\"10\":1}}],[\"responsible\",{\"1\":{\"22\":1,\"24\":1}}],[\"responsemessage\",{\"1\":{\"26\":3}}],[\"responsegenerator\",{\"1\":{\"24\":1}}],[\"responses\",{\"1\":{\"24\":2}}],[\"response\",{\"1\":{\"8\":5,\"24\":1,\"26\":1}}],[\"requires\",{\"1\":{\"21\":1,\"25\":1}}],[\"required\",{\"1\":{\"17\":2,\"21\":3,\"25\":3}}],[\"requirements\",{\"1\":{\"3\":1}}],[\"relevant\",{\"1\":{\"15\":1}}],[\"related\",{\"1\":{\"8\":7}}],[\"representation\",{\"1\":{\"15\":1}}],[\"repository\",{\"1\":{\"3\":1}}],[\"retrieving\",{\"1\":{\"15\":1}}],[\"retrieval\",{\"1\":{\"9\":1}}],[\"retrieve\",{\"1\":{\"8\":1,\"20\":1,\"22\":2}}],[\"returning\",{\"1\":{\"17\":1}}],[\"return\",{\"1\":{\"8\":3,\"17\":2}}],[\"regist\",{\"1\":{\"10\":1}}],[\"registry\",{\"1\":{\"7\":1}}],[\"registerrag\",{\"1\":{\"3\":2}}],[\"register\",{\"1\":{\"2\":6,\"3\":4,\"4\":1,\"5\":2,\"7\":1,\"8\":4,\"9\":1,\"10\":1,\"13\":1,\"15\":3,\"17\":1,\"19\":1,\"22\":1}}],[\"refer\",{\"1\":{\"7\":2,\"11\":1,\"19\":1}}],[\"remotegenerator\",{\"1\":{\"26\":1}}],[\"remoteembeddinggetter\",{\"1\":{\"17\":1}}],[\"remote\",{\"1\":{\"6\":4,\"15\":2,\"16\":14,\"18\":1,\"20\":2,\"21\":10,\"25\":11,\"27\":1,\"30\":2}}],[\"rerank\",{\"1\":{\"5\":1}}],[\"recommended\",{\"1\":{\"2\":1}}],[\"rag\",{\"1\":{\"2\":6,\"3\":4,\"4\":1,\"5\":2,\"6\":1,\"7\":1,\"8\":4,\"9\":2,\"10\":4,\"13\":1,\"15\":3,\"17\":1,\"19\":2}}],[\"system\",{\"1\":{\"26\":3}}],[\"same\",{\"1\":{\"20\":1}}],[\"soon\",{\"1\":{\"14\":1}}],[\"source\",{\"0\":{\"3\":1},\"1\":{\"1\":1,\"3\":1,\"11\":1,\"12\":2,\"28\":1}}],[\"s\",{\"1\":{\"10\":1,\"20\":1,\"22\":1}}],[\"specifies\",{\"1\":{\"16\":2}}],[\"specify\",{\"1\":{\"7\":1,\"16\":1}}],[\"split\",{\"1\":{\"8\":2}}],[\"splitter=charactersplitter\",{\"1\":{\"8\":1}}],[\"splitters\",{\"1\":{\"8\":1}}],[\"splitter\",{\"1\":{\"8\":1}}],[\"src=modelscope\",{\"1\":{\"7\":1}}],[\"separate\",{\"1\":{\"30\":1}}],[\"see\",{\"1\":{\"28\":1}}],[\"search\",{\"1\":{\"22\":4}}],[\"section\",{\"1\":{\"19\":1}}],[\"sentence\",{\"1\":{\"18\":1}}],[\"sentencetransformerembeddinggetter\",{\"1\":{\"18\":1}}],[\"server\",{\"1\":{\"15\":1,\"16\":3}}],[\"service\",{\"0\":{\"7\":1},\"1\":{\"7\":6,\"25\":5,\"27\":2,\"29\":1,\"30\":2}}],[\"self\",{\"1\":{\"8\":1,\"17\":1,\"22\":4,\"26\":1}}],[\"settings\",{\"1\":{\"16\":1,\"21\":1}}],[\"setting\",{\"1\":{\"16\":1}}],[\"set\",{\"1\":{\"7\":1,\"10\":3,\"23\":1,\"30\":1}}],[\"several\",{\"1\":{\"5\":1}}],[\"single\",{\"1\":{\"22\":1}}],[\"similar\",{\"1\":{\"20\":1,\"22\":1}}],[\"simple\",{\"1\":{\"2\":1,\"6\":1,\"9\":1}}],[\"site\",{\"1\":{\"12\":1}}],[\"size\",{\"1\":{\"6\":1,\"29\":3,\"30\":1}}],[\"shown\",{\"1\":{\"6\":1}}],[\"should\",{\"1\":{\"2\":1,\"7\":2,\"10\":1,\"16\":1,\"18\":3,\"23\":1,\"24\":2,\"27\":3}}],[\"str\",{\"1\":{\"16\":4,\"17\":2,\"21\":4,\"22\":7,\"25\":4,\"26\":4,\"29\":5}}],[\"streamline\",{\"1\":{\"12\":1,\"28\":1}}],[\"static\",{\"1\":{\"12\":1}}],[\"starting\",{\"1\":{\"7\":1}}],[\"start\",{\"0\":{\"5\":1},\"1\":{\"7\":4,\"16\":1}}],[\"storefactory\",{\"1\":{\"22\":2}}],[\"storeconfig\",{\"1\":{\"21\":1}}],[\"stored\",{\"1\":{\"20\":1,\"21\":1}}],[\"store\",{\"0\":{\"20\":1,\"22\":1,\"23\":1},\"1\":{\"5\":1,\"6\":4,\"20\":5,\"21\":21,\"22\":4}}],[\"suggestions\",{\"1\":{\"14\":1}}],[\"sure\",{\"1\":{\"7\":1}}],[\"such\",{\"1\":{\"5\":1}}],[\"successful\",{\"1\":{\"2\":1,\"3\":1}}],[\"supports\",{\"1\":{\"10\":1}}],[\"support\",{\"1\":{\"2\":1,\"10\":1}}],[\"auto\",{\"1\":{\"29\":1}}],[\"augmented\",{\"1\":{\"9\":1}}],[\"abstract\",{\"1\":{\"20\":1,\"22\":3,\"26\":2}}],[\"above\",{\"1\":{\"7\":2}}],[\"api\",{\"1\":{\"19\":1}}],[\"applicable\",{\"1\":{\"16\":2}}],[\"approach\",{\"1\":{\"15\":1}}],[\"array\",{\"1\":{\"28\":1}}],[\"args=\",{\"1\":{\"17\":2}}],[\"args\",{\"1\":{\"17\":4}}],[\"are\",{\"1\":{\"12\":1,\"16\":1,\"21\":2,\"22\":1,\"26\":1}}],[\"at\",{\"1\":{\"16\":1,\"22\":1}}],[\"ai\",{\"1\":{\"12\":1,\"28\":1}}],[\"accessing\",{\"1\":{\"16\":1}}],[\"accessible\",{\"1\":{\"16\":1}}],[\"acknowledgements\",{\"0\":{\"12\":1}}],[\"activate\",{\"1\":{\"2\":1}}],[\"add\",{\"0\":{\"17\":1,\"22\":1,\"26\":1},\"1\":{\"8\":1,\"10\":1,\"19\":1,\"22\":6}}],[\"await\",{\"1\":{\"8\":3,\"17\":1}}],[\"after\",{\"1\":{\"7\":1,\"17\":3,\"22\":1}}],[\"alternatively\",{\"1\":{\"17\":1}}],[\"all\",{\"1\":{\"7\":1}}],[\"aliyuncs\",{\"1\":{\"7\":1}}],[\"aliyun\",{\"1\":{\"7\":1}}],[\"also\",{\"1\":{\"3\":1,\"4\":1,\"10\":1,\"19\":1}}],[\"any\",{\"1\":{\"14\":1,\"17\":3}}],[\"an\",{\"1\":{\"7\":1,\"12\":1,\"16\":1,\"28\":1}}],[\"and\",{\"1\":{\"2\":1,\"5\":1,\"6\":1,\"7\":3,\"8\":1,\"9\":1,\"10\":1,\"12\":2,\"15\":1,\"16\":2,\"17\":2,\"20\":4,\"21\":2,\"22\":3,\"24\":1,\"25\":2,\"26\":2,\"28\":1,\"30\":2}}],[\"assistant\",{\"1\":{\"26\":1}}],[\"ask\",{\"1\":{\"8\":1}}],[\"asynchronous\",{\"1\":{\"10\":2}}],[\"async\",{\"1\":{\"8\":1,\"17\":1,\"22\":4,\"26\":1}}],[\"asyncio\",{\"1\":{\"8\":2}}],[\"as\",{\"1\":{\"5\":1,\"7\":1,\"14\":2,\"16\":1,\"20\":2,\"21\":1,\"22\":1,\"26\":2}}],[\"a\",{\"0\":{\"17\":1,\"22\":1,\"26\":1},\"1\":{\"2\":2,\"5\":2,\"6\":2,\"7\":1,\"8\":1,\"9\":2,\"10\":2,\"12\":3,\"15\":3,\"17\":1,\"20\":4,\"21\":1,\"22\":8,\"24\":3,\"25\":1,\"26\":2,\"27\":3,\"28\":1,\"30\":1}}],[\"available\",{\"0\":{\"18\":1,\"23\":1,\"27\":1},\"1\":{\"1\":1,\"2\":1,\"7\":1,\"11\":1}}],[\"ids\",{\"1\":{\"22\":2}}],[\"id\",{\"1\":{\"16\":1,\"22\":10}}],[\"its\",{\"1\":{\"22\":2}}],[\"it\",{\"1\":{\"10\":4,\"15\":2,\"19\":1,\"20\":2,\"21\":4,\"25\":6}}],[\"improve\",{\"1\":{\"22\":3}}],[\"implementing\",{\"1\":{\"22\":1}}],[\"implements\",{\"1\":{\"22\":1,\"26\":1}}],[\"implement\",{\"1\":{\"10\":1,\"17\":2}}],[\"import\",{\"1\":{\"2\":1,\"3\":1,\"8\":5}}],[\"image\",{\"1\":{\"7\":4,\"10\":1}}],[\"indicate\",{\"1\":{\"30\":1}}],[\"inference\",{\"1\":{\"28\":1}}],[\"information\",{\"1\":{\"2\":1,\"7\":3,\"13\":1,\"15\":1,\"19\":1,\"28\":1}}],[\"involves\",{\"1\":{\"15\":1}}],[\"input\",{\"1\":{\"15\":1}}],[\"inherits\",{\"1\":{\"22\":1,\"26\":2}}],[\"inherit\",{\"1\":{\"10\":1,\"17\":2}}],[\"int\",{\"1\":{\"22\":1}}],[\"integrate\",{\"1\":{\"17\":1,\"22\":1,\"26\":1}}],[\"integration\",{\"1\":{\"12\":1,\"28\":1}}],[\"introduce\",{\"1\":{\"15\":1,\"19\":1}}],[\"introduction\",{\"0\":{\"9\":1,\"24\":1}}],[\"into\",{\"1\":{\"5\":1,\"15\":1,\"16\":1,\"20\":1}}],[\"instructions\",{\"1\":{\"11\":1}}],[\"instruct\",{\"1\":{\"6\":1,\"30\":3}}],[\"installed\",{\"1\":{\"7\":1}}],[\"install\",{\"1\":{\"2\":4,\"3\":5,\"10\":1}}],[\"installation\",{\"0\":{\"1\":1,\"11\":1},\"1\":{\"2\":1,\"3\":1,\"11\":2}}],[\"including\",{\"1\":{\"5\":1}}],[\"in\",{\"1\":{\"5\":2,\"6\":1,\"10\":2,\"11\":1,\"12\":1,\"15\":1,\"16\":3,\"17\":1,\"19\":1,\"20\":4,\"21\":2,\"22\":4,\"23\":1,\"25\":1,\"29\":1}}],[\"if\",{\"1\":{\"2\":2,\"3\":1,\"7\":4,\"14\":1,\"17\":2,\"22\":1,\"25\":1}}],[\"issues\",{\"1\":{\"14\":1}}],[\"is\",{\"1\":{\"1\":1,\"2\":4,\"3\":1,\"5\":1,\"6\":1,\"7\":1,\"8\":1,\"10\":4,\"11\":1,\"12\":1,\"15\":2,\"16\":5,\"17\":2,\"19\":1,\"20\":5,\"21\":7,\"22\":2,\"24\":2,\"25\":8,\"26\":1,\"28\":1,\"29\":1,\"30\":5}}]],\"serializationVersion\":2},\"/zh/\":{\"documentCount\":30,\"nextId\":30,\"documentIds\":{\"0\":\"8\",\"1\":\"12\",\"2\":\"12#通过-pip-安装\",\"3\":\"12#从源码安装\",\"4\":\"12#docker\",\"5\":\"13\",\"6\":\"13#基本配置\",\"7\":\"13#xinference-服务\",\"8\":\"13#pipeline\",\"9\":\"14\",\"10\":\"14#🌟-特性\",\"11\":\"14#🙏-致谢\",\"12\":\"14#🤝-贡献\",\"13\":\"14#✉️-联系我们\",\"14\":\"15\",\"15\":\"15#基本配置\",\"16\":\"15#如何添加新的-embedding-模型\",\"17\":\"15#可用的-embedding-模型\",\"18\":\"16\",\"19\":\"17\",\"20\":\"17#基本配置\",\"21\":\"17#如何添加新的存储组件\",\"22\":\"17#可用的存储组件\",\"23\":\"18\",\"24\":\"18#基本配置\",\"25\":\"18#如何添加新的生成组件\",\"26\":\"18#可用的生成组件\",\"27\":\"19\",\"28\":\"19#基本配置\",\"29\":\"19#示例配置\"},\"fieldIds\":{\"h\":0,\"t\":1,\"c\":2},\"fieldLength\":{\"0\":[1],\"1\":[2,3],\"2\":[3,31],\"3\":[1,33],\"4\":[1,6],\"5\":[1,24],\"6\":[1,36],\"7\":[2,80],\"8\":[1,63],\"9\":[1,8],\"10\":[2,19],\"11\":[2,23],\"12\":[2,6],\"13\":[2,5],\"14\":[1,22],\"15\":[1,71],\"16\":[3,51],\"17\":[3,15],\"18\":[1,15],\"19\":[1,28],\"20\":[1,39],\"21\":[1,55],\"22\":[1,5],\"23\":[1,16],\"24\":[1,50],\"25\":[1,33],\"26\":[1,22],\"27\":[2,11],\"28\":[1,29],\"29\":[1,30]},\"averageFieldLength\":[1.4333333333333333,27.633333333333333],\"storedFields\":{\"0\":{\"h\":\"\"},\"1\":{\"h\":\"Installation Guide\",\"t\":[\"Note: 目前只支持从源码安装。\"]},\"2\":{\"h\":\"通过 pip 安装\",\"t\":[\"最简单的方法是通过 pip 进行安装。首先，你需要安装 pytorch。你可以在这里找到安装方法。\",\"conda create -n register-rag python==3.10 conda activate register-rag pip3 install torch torchvision torchaudio # Cuda 12.1 pip3 install register-rag\",\"然后，你可以运行以下命令来检查安装是否成功。\",\"python -c \\\"import register_rag; print(register_rag.__version__)\\\"\"]},\"3\":{\"h\":\"从源码安装\",\"t\":[\"你也可以从源码安装 Register RAG。首先，你需要克隆仓库。\",\"git clone https://github.com/Charon-ops/RegisterRAG.git\\\" cd RegisterRAG\",\"之后，需要安装依赖。\",\"pip install -r requirements.txt\",\"最后，直接安装 Register RAG。\",\"pip install -e .\",\"你可以运行以下命令来检查安装是否成功。\",\"python -c \\\"import register_rag; print(register_rag.__version__)\\\"\"]},\"4\":{\"h\":\"Docker\",\"t\":[\"我们也提供了一个 Docker 镜像，你可以通过以下命令拉取镜像。（开发中）\"]},\"5\":{\"h\":\"快速入门\",\"t\":[\"在这一部分，我们将介绍如何搭建一个基本的 Register RAG pipeline。\",\"Register RAG 使用 json 文件来进行整个 pipeline 的配置。目前，配置文件有四个部分：embedding、store、generation 和 prompt。其中，prompt 部分可以选择不配置。预计未来最少会加入两个模块：重排序（rerank）和网络搜索（websearch）。\"]},\"6\":{\"h\":\"基本配置\",\"t\":[\"下面是一个基本的配置文件，我们将使用这个配置文件来搭建一个简单的 RAG pipeline。\",\"{ \\\"embedding\\\": { \\\"embedding_type\\\": \\\"remote\\\", \\\"embedding_model_name_or_path\\\": \\\"xinference/bge-m3\\\", \\\"embedding_remote_url\\\": \\\"http://localhost:9997\\\", \\\"embedding_model_preload\\\": true }, \\\"store\\\": { \\\"store_type\\\": \\\"local\\\", \\\"store_name\\\": \\\"chroma\\\", \\\"store_local_path\\\": \\\"/path/to/chroma\\\" }, \\\"generation\\\": { \\\"generation_type\\\": \\\"remote\\\", \\\"generation_model_name_or_path\\\": \\\"xinference/qwen2-instruct\\\", \\\"generation_remote_url\\\": \\\"http://localhost:9997\\\", \\\"generation_xinference_config\\\": { \\\"xinference_model_size\\\": \\\"1_5\\\", \\\"xinference_mdoel_quantization\\\": \\\"4-bit\\\" } } }\"]},\"7\":{\"h\":\"Xinference 服务\",\"t\":[\"如果你希望使用上面的配置搭建自己的 RAG pipeline,那么需要首先启动 xinference 服务。你可以访问xinference 文档来获取更多信息。\",\"在这个例子中，我们将使用 docker 来启动 xinference 服务。首先，我们需要拉取 xinference 镜像。\",\"# 国内用户可以使用下面的命令从阿里云拉取镜像 docker pull registry.cn-hangzhou.aliyuncs.com/xprobe_xinference/xinference:latest # 或者也可以从 Docker Hub 拉取镜像 docker pull xprobe/xinference:latest\",\"之后，我们需要确认已经安装了 NVIDIA 驱动和 NVIDIA Container Toolkit。NVIDIA Container Toolkit的文档可以在这里找到。\",\"最后，我们可以使用这条命令来启动 xinference 服务：\",\"docker run -e XINFERENCE_MODEL_SRC=modelscope -p 9997:9997 --gpus all xprobe/xinference:latest xinference-local -H 0.0.0.0 --log-level debug\",\"Note: --gpus 和 -H 参数必须设置,并且主机的 CUDA 版本必须大于等于 12.4。如果有多个 GPU,可以使用 --gpus 0,1,2 来制定所需要使用的 GPU。上述镜像只能在有 GPU 的机器上运行，如果需要使用 CPU 版本，可以前往xinference 文档获取更多信息。\",\"在启动 xinference 服务之后，可以访问 http://localhost:9997 来检查服务是否正常运行。\"]},\"8\":{\"h\":\"Pipeline\",\"t\":[\"可以通过下面的代码来完成一个简单的 RAG pipeline。\",\"import asyncio from register_rag import Pipeline from register_rag.documents import Document from register_rag.documents.loader import PDFLoader from register_rag.documents.splitter import CharacterSplitter async def main(): pipeline = Pipeline(\\\"path/to/your/configuration.json\\\") loader = PDFLoader(\\\"path/to/your/pdf\\\") # 使用换行符分割文档 docs = await loader.load_and_split(splitter=CharacterSplitter()) collection_name = \\\"default\\\" await self.pipeline.add_docs(docs, collection_name) # 生成回复 query = \\\"What is the capital of China?\\\" # 问题 top_k = 5 # 召回的文档数量 return_related_docs = True # 是否需要返回召回结果 response, related_docs = await pipeline.get_response( query, collection_name, top_k, return_related_docs ) print(f\\\"Response: {response}\\\") print(f\\\"Related Docs: {related_docs}\\\") asyncio.run(main())\"]},\"9\":{\"h\":\"简介\",\"t\":[\"Register RAG 提供了一种简单、高度可自定义、用于构建 RAG（检索增强生成）任务的流程的框架。\"]},\"10\":{\"h\":\"🌟 特性\",\"t\":[\"高度可自定义\",\"你可以使用我们提供的组件，通过修改配置文件搭建自己的框架。\",\"你也可以简单地添加自己的组件。你只需要继承基类，实现必需的方法，并且在工厂中注册你的组件，就可以在配置文件中使用你的组件了。\",\"安装简便\",\"可以通过pip快速安装（开发中）\",\"可以通过docker镜像运行（开发中）\",\"完全支持异步操作\",\"在设计之初，Register RAG 就考虑到了异步操作。你可以轻松地并行运行多个组件。\"]},\"11\":{\"h\":\"🙏 致谢\",\"t\":[\"我们十分感谢前任所做的工作，这些工作为我们框架的搭建提供了很大的帮助。以下是我们使用的开源项目列表，排名不分先后：\",\"Xinference: 可以简化各种 AI 模型的运行和集成。更多信息可以点击这里查看。\",\"Ollama: 可以快速部署 LLM。更多信息可以在这里找到。\",\"VuePress: 一个简单的静态网站搭建框架。更多信息可以在这里找到。\",\"vuepress-theme-hope: 一个具有强大功能的 vuepress 主题。更多信息可以在这里找到。\",\"chroma: 一个开源的向量数据库。更多信息可以在这里找到。\"]},\"12\":{\"h\":\"🤝 贡献\",\"t\":[\"我们欢迎更多开发者为 Register RAG 贡献代码！请查看贡献指南获取更多信息。\"]},\"13\":{\"h\":\"✉️ 联系我们\",\"t\":[\"如果你有任何问题或建议，请通过邮件或GitHub Issues联系我们。我们会尽快回复你。\"]},\"14\":{\"h\":\"Embedding\",\"t\":[\"Embedding 是 Register RAG 中最重要的组件之一。它将输入文本转换为向量表示，并将转换后的向量用于从数据库中检索相关信息。\",\"Register RAG 提供了两种 Embedding 类型：\",\"local : 这种方法需要从本地文件系统加载模型，并且直接在本地机器上运行。\",\"remote : 这种方法需要从远程服务器或 Docker 容器加载模型，模型并不直接在本地机器上运行。\",\"接下来，我们将介绍如何在 Register RAG 中使用 Embedding 组件。\"]},\"15\":{\"h\":\"基本配置\",\"t\":[\"以下是 Python 代码中 Embedding 的配置：\",\"class EmbeddingConfig(BaseModel): embedding_type: Literal[\\\"local\\\", \\\"remote\\\"] embedding_model_name_or_path: Optional[str] = None embedding_model_device: str = \\\"cpu\\\" embedding_model_preload: bool = False embedding_remote_url: Optional[str] = None embedding_remote_token: Optional[str] = None\",\"embedding_type: 指定 Embedding 是本地还是远程。\",\"embedding_model_name_or_path: Embedding 模型的名称或路径。如果 embedding_type 被设置为 remote，那么远程服务器需要具有所指定的模型名称或者路径的访问权限。\",\"embedding_model_device: 指定模型运行的设备（CPU 或 CUDA）。对于多个 GPU，可以指定 GPU ID（例如，cuda:0）。\",\"embedding_model_preload: 是否在尚未调用 get_embedding 方法时预加载模型。该设置仅适用于本地 Embedding。\",\"embedding_remote_url: 远程服务器的 URL，仅适用于远程 Embedding。\",\"embedding_remote_token: 访问远程服务器的可选 token，仅适用于远程 Embedding。\",\"在配置文件（JSON 格式）中，Embedding 的设置如下：\",\"{ \\\"embedding\\\": { \\\"embedding_type\\\": \\\"remote\\\", \\\"embedding_model_name_or_path\\\": \\\"xinference/bge-m3\\\", \\\"embedding_remote_url\\\": \\\"http://localhost:9997\\\", \\\"embedding_model_preload\\\": true } }\",\"embedding_model_name_or_path 由 / 分隔为两部分：Embedding 模型的类名和模型名称。类名用于在代码中定位相应的类，而模型名称用于加载模型。\"]},\"16\":{\"h\":\"如何添加新的 Embedding 模型\",\"t\":[\"要集成新的 Embedding 模型，需要继承 register_rag.embedding 中的 EmbeddingGetter 类，或者直接继承 LocalEmbeddingGetter 或 RemoteEmbeddingGetter，并实现 embedding 方法。如果需要预处理或后处理，可以实现 pre_embedding 或 post_embedding 方法。通过 get_embedding 方法传递所需的参数：\",\"async def get_embedding( self, docs: List[Document], pre_args: Dict[str, Any] = None, after_args: Dict[str, Any] = None, ) -> List[List[float]]:\",\"调用带有参数的 get_embedding 的示例：\",\"embedding = await embedding_getter.get_embedding( docs, pre_args={\\\"pre_args\\\": \\\"value\\\"}, after_args={\\\"after_args\\\": \\\"value\\\"}, )\",\"Note: pre_embedding 和 post_embedding 方法返回 None。get_embedding 方法不关心这些方法的返回值。如果希望使用返回值，需要重写 get_embedding 方法。\"]},\"17\":{\"h\":\"可用的 Embedding 模型\",\"t\":[\"local: \",\"BertEmbeddingGetter: 配置为 bert/model_name_or_path.\",\"SentenceTransformerEmbeddingGetter: 配置为 sentence_transformer/model_name_or_path.\",\"remote: \",\"XinferenceEmbeddingGetter: 配置为 xinference/model_name_or_path.\"]},\"18\":{\"h\":\"指南\",\"t\":[\"在这一部分，我们将介绍如何使用 Register RAG 构建自己的 RAG pipeline。\",\"你可以使用我们提供的组件快速搭建自己的 pipeline。同时，也可以轻松地添加自己的组件到 pipeline 中。\",\"更多详细信息，请参阅 API 文档。\"]},\"19\":{\"h\":\"存储\",\"t\":[\"存储组件用于将文档及与其相应的 embedding 存储在数据库中。当用户提出问题时，系统会将问题的 embedding 与数据库中存储的 embedding 进行比较，以检索出最相似的文档。\",\"存储组件是一个复杂的组件，包含多个抽象方法。与嵌入组件一样，存储组件也分为两类：\",\"local: Store the embeddings and documents directly in local disk.\",\"remote: Store the embeddings and documents in a remote database or a Docker container.\"]},\"20\":{\"h\":\"基本配置\",\"t\":[\"以下是 Python 中存储组件的配置：\",\"class StoreConfig(BaseModel): store_type: Literal[\\\"local\\\", \\\"remote\\\"] store_name: Optional[str] = None store_remote_url: Optional[str] = None store_remote_token: Optional[str] = None store_local_path: Optional[str] = None\",\"store_type: 存储组件的类型。可以是 local 或 remote。\",\"store_name: 存储组件的名称。用于区分不同的存储组件。\",\"store_remote_url: 远程数据库的 URL。仅当 store_type 为 remote 时需要。\",\"store_remote_token: 远程数据库的 token。仅当 store_type 为 remote，且数据库需要 token 时需要。\",\"store_local_path: 存储嵌入和文档的本地目录路径。仅当 store_type 为 local 时需要。\",\"在配置文件中（JSON 格式），存储设置如下所示：\",\"{ \\\"store\\\": { \\\"store_type\\\": \\\"local\\\", \\\"store_name\\\": \\\"chroma\\\", \\\"store_local_path\\\": \\\"/path/to/data\\\" } }\"]},\"21\":{\"h\":\"如何添加新的存储组件\",\"t\":[\"要集成新的存储组件，需要创建一个新的类，该类继承自 Store 类并实现抽象方法。抽象方法如下：\",\"add_document: 将单个文档及其 embedding 添加到数据库中。\",\" async def add_document( self, document: Document, embedding: List[float], collection_name: str, id: str = None, ) -> None: ```python async def add_document( self, document: Document, embedding: List[float], collection_name: str, id: str = None, ) -> None:\",\"add_documents 方法默认调用 add_document 方法。如果有更高效的实现方式，可以重写该方法。\",\"search_by_embedding: 根据给定 embedding 检索最相似的文档。\",\"async def search_by_embedding( self, embedding: List[float], collection_name: str, top_k: int = 5 ) -> List[Document]:\",\"search_by_embeddings 方法默认不提供。如果需要一次搜索多个 embedding，可以添加该方法。\",\"get_id_by_document: 根据文档内容检索文档的 ID。\",\"async def get_id_by_document( self, document: Document, collection_name: str ) -> str:\",\"get_ids_by_documents 方法默认调用 get_id_by_document 方法。如果有更高效的实现方式，可以重写该方法。\",\"delete_by_id: 根据文档 ID 从数据库中删除文档及其 embedding。\",\"async def delete_by_id( self, id: str, collection_name: str ) -> None:\",\"delete_by_ids 方法默认调用 delete_by_id 方法。如果有更高效的实现方式，可以重写该方法。\",\"实现完抽象方法后，需要在 StoreFactory 类中注册新的存储组件。StoreFactory 类负责根据配置创建存储组件。\"]},\"22\":{\"h\":\"可用的存储组件\",\"t\":[\"local\",\"ChromaStore : 配置文件中的名称应设置为 chroma。\"]},\"23\":{\"h\":\"简介\",\"t\":[\"生成组件负责根据 prompt 生成对应的回复。当给定一个用户提出的问题时，经过召回，需要将召回结果与用户的问题结合生成 prompt,这一部分由 PromptGenerator 负责，并不由生成组件负责。生成组件是一个 Generator，根据 PromptGenerator 生成的 prompt 生成回复。\"]},\"24\":{\"h\":\"基本配置\",\"t\":[\"以下是 Python 中生成组件的配置：\",\"class GenerationConfig(BaseModel): generation_type: Literal[\\\"local\\\", \\\"remote\\\"] generation_model_name_or_path: Optional[str] = None generation_model_preload: bool = False generation_model_device: str = \\\"cpu\\\" generation_remote_url: Optional[str] = None generation_remote_token: Optional[str] = None generation_xinference_config: Optional[XinferenceConfig] = None\",\"generation_type: 生成组件的类型。可以是 local 或 remote。\",\"generation_model_name_or_path: 用于生成的模型的名称或路径。\",\"generation_model_preload: 是否在调用之前加载模型。\",\"generation_model_device: 用于生成的设备。可以是 cpu 或 cuda，也可以指定具体的 GPU 编号。\",\"generation_remote_url: 远程生成服务的 URL。仅当 generation_type 为 remote 时需要。\",\"generation_remote_token: 远程生成服务的 token。仅当 generation_type 为 remote 且服务需要 token 时需要。\",\"generation_xinference_config: Xinference 服务的配置。仅当 generation_type 为 remote 且使用 Xinference 服务时需要。\"]},\"25\":{\"h\":\"如何添加新的生成组件\",\"t\":[\"如果需要添加自定义的生成组件，需要继承 Generator 类，或者继承 LocalGenerator、RemoteGenerator 类，并实现抽象方法。抽象方法如下：\",\"generate: 根据 prompt、system prompt 与历史消息生成回复。\",\" async def generate( self, prompt: str, history: List[ResponseMessage] = None, system_prompt: str = None, ) -> str:\",\"ResponseMessage 定义如下：\",\"class ResponseMessage(TypedDict): content: str role: Literal[\\\"system\\\", \\\"user\\\", \\\"assistant\\\"]\"]},\"26\":{\"h\":\"可用的生成组件\",\"t\":[\"local: \",\"TransformersGenerator: 使用 Transformers 库进行本地生成的生成器。model_name_or_path 应配置为 transformers/xxx。\",\"remote: \",\"OllamaGenerator: 调用 Ollama 服务进行生成的生成器。model_name_or_path 应配置为 ollama/xxx。\",\"XinfernceGenerator: 调用 Xinference 服务进行生成的生成器。model_name_or_path 应配置为 xinference/xxx。\"]},\"27\":{\"h\":\"Xinference 配置\",\"t\":[\"Xorbits Inference (Xinference) 是一个开源平台，用于简化各种 AI 模型的操作和集成。有关更多信息，请参阅 Xinference 文档。\"]},\"28\":{\"h\":\"基本配置\",\"t\":[\"下面是 Python 中 Xinference 服务的配置：\",\"class XinferenceConfig(BaseModel): xinference_model_engine: str = \\\"Transformers\\\" xinference_model_format: str = \\\"pytorch\\\" xinference_ngpu: str = \\\"auto\\\" xinference_model_size: str xinference_mdoel_quantization: str\",\"xinference_model_engine: 模型使用的引擎。\",\"xinference_model_format: 模型的格式。\",\"xinference_ngpu: 使用的 GPU 数量。\",\"xinference_model_size: 模型的大小。\",\"xinference_mdoel_quantization: 模型的量化属性。\"]},\"29\":{\"h\":\"示例配置\",\"t\":[\"{ \\\"generation\\\": { \\\"generation_type\\\": \\\"remote\\\", \\\"generation_model_name_or_path\\\": \\\"xinference/qwen2-instruct\\\", \\\"generation_remote_url\\\": \\\"http://localhost:9997\\\", \\\"generation_xinference_config\\\": { \\\"xinference_model_size\\\": \\\"1_5\\\", \\\"xinference_mdoel_quantization\\\": \\\"4-bit\\\" } } }\",\"Note: 模型名称也分为两个部分，第一个部分用于确定对应的类名，第二部分用于确定加载的模型名称（或路径），两者之间通过 / 进行分割。\"]}},\"dirtCount\":0,\"index\":[[\"两者之间通过\",{\"1\":{\"29\":1}}],[\"第二部分用于确定加载的模型名称\",{\"1\":{\"29\":1}}],[\"第一个部分用于确定对应的类名\",{\"1\":{\"29\":1}}],[\"示例配置\",{\"0\":{\"29\":1}}],[\"数量\",{\"1\":{\"28\":1}}],[\"下面是\",{\"1\":{\"28\":1}}],[\"下面是一个基本的配置文件\",{\"1\":{\"6\":1}}],[\"有关更多信息\",{\"1\":{\"27\":1}}],[\"调用\",{\"1\":{\"26\":2}}],[\"调用带有参数的\",{\"1\":{\"16\":1}}],[\"应配置为\",{\"1\":{\"26\":3}}],[\"库进行本地生成的生成器\",{\"1\":{\"26\":1}}],[\"user\",{\"1\":{\"25\":1}}],[\"url\",{\"1\":{\"6\":2,\"15\":4,\"20\":3,\"24\":3,\"29\":1}}],[\"定义如下\",{\"1\":{\"25\":1}}],[\"且使用\",{\"1\":{\"24\":1}}],[\"且服务需要\",{\"1\":{\"24\":1}}],[\"且数据库需要\",{\"1\":{\"20\":1}}],[\"编号\",{\"1\":{\"24\":1}}],[\"也可以指定具体的\",{\"1\":{\"24\":1}}],[\"也可以轻松地添加自己的组件到\",{\"1\":{\"18\":1}}],[\"负责\",{\"1\":{\"23\":1}}],[\"经过召回\",{\"1\":{\"23\":1}}],[\"当给定一个用户提出的问题时\",{\"1\":{\"23\":1}}],[\"当用户提出问题时\",{\"1\":{\"19\":1}}],[\"生成的\",{\"1\":{\"23\":1}}],[\"生成组件的类型\",{\"1\":{\"24\":1}}],[\"生成组件是一个\",{\"1\":{\"23\":1}}],[\"生成组件负责根据\",{\"1\":{\"23\":1}}],[\"生成对应的回复\",{\"1\":{\"23\":1}}],[\"生成回复\",{\"1\":{\"8\":1,\"23\":1}}],[\"实现完抽象方法后\",{\"1\":{\"21\":1}}],[\"实现必需的方法\",{\"1\":{\"10\":1}}],[\"从数据库中删除文档及其\",{\"1\":{\"21\":1}}],[\"从源码安装\",{\"0\":{\"3\":1}}],[\"根据\",{\"1\":{\"23\":1,\"25\":1}}],[\"根据文档\",{\"1\":{\"21\":1}}],[\"根据文档内容检索文档的\",{\"1\":{\"21\":1}}],[\"根据给定\",{\"1\":{\"21\":1}}],[\"检索最相似的文档\",{\"1\":{\"21\":1}}],[\"检索增强生成\",{\"1\":{\"9\":1}}],[\"```python\",{\"1\":{\"21\":1}}],[\"添加到数据库中\",{\"1\":{\"21\":1}}],[\"将单个文档及其\",{\"1\":{\"21\":1}}],[\"抽象方法如下\",{\"1\":{\"21\":1,\"25\":1}}],[\"该类继承自\",{\"1\":{\"21\":1}}],[\"该设置仅适用于本地\",{\"1\":{\"15\":1}}],[\"时需要\",{\"1\":{\"20\":3,\"24\":2}}],[\"为\",{\"1\":{\"20\":3,\"24\":3}}],[\"仅当\",{\"1\":{\"20\":3,\"24\":3}}],[\"仅适用于远程\",{\"1\":{\"15\":2}}],[\"远程生成服务的\",{\"1\":{\"24\":2}}],[\"远程数据库的\",{\"1\":{\"20\":2}}],[\"远程服务器的\",{\"1\":{\"15\":1}}],[\"用于简化各种\",{\"1\":{\"27\":1}}],[\"用于生成的设备\",{\"1\":{\"24\":1}}],[\"用于生成的模型的名称或路径\",{\"1\":{\"24\":1}}],[\"用于区分不同的存储组件\",{\"1\":{\"20\":1}}],[\"用于构建\",{\"1\":{\"9\":1}}],[\"与历史消息生成回复\",{\"1\":{\"25\":1}}],[\"与嵌入组件一样\",{\"1\":{\"19\":1}}],[\"与数据库中存储的\",{\"1\":{\"19\":1}}],[\"包含多个抽象方法\",{\"1\":{\"19\":1}}],[\"以检索出最相似的文档\",{\"1\":{\"19\":1}}],[\"以下是\",{\"1\":{\"15\":1,\"20\":1,\"24\":1}}],[\"以下是我们使用的开源项目列表\",{\"1\":{\"11\":1}}],[\"进行分割\",{\"1\":{\"29\":1}}],[\"进行比较\",{\"1\":{\"19\":1}}],[\"进行安装\",{\"1\":{\"2\":1}}],[\"系统会将问题的\",{\"1\":{\"19\":1}}],[\"存储设置如下所示\",{\"1\":{\"20\":1}}],[\"存储嵌入和文档的本地目录路径\",{\"1\":{\"20\":1}}],[\"存储组件的名称\",{\"1\":{\"20\":1}}],[\"存储组件的类型\",{\"1\":{\"20\":1}}],[\"存储组件也分为两类\",{\"1\":{\"19\":1}}],[\"存储组件是一个复杂的组件\",{\"1\":{\"19\":1}}],[\"存储组件用于将文档及与其相应的\",{\"1\":{\"19\":1}}],[\"存储在数据库中\",{\"1\":{\"19\":1}}],[\"存储\",{\"0\":{\"19\":1}}],[\"更多详细信息\",{\"1\":{\"18\":1}}],[\"更多信息可以在这里找到\",{\"1\":{\"11\":4}}],[\"更多信息可以点击这里查看\",{\"1\":{\"11\":1}}],[\"同时\",{\"1\":{\"18\":1}}],[\"构建自己的\",{\"1\":{\"18\":1}}],[\"指南\",{\"0\":{\"18\":1}}],[\"指定模型运行的设备\",{\"1\":{\"15\":1}}],[\"指定\",{\"1\":{\"15\":1}}],[\"配置\",{\"0\":{\"27\":1}}],[\"配置文件中的名称应设置为\",{\"1\":{\"22\":1}}],[\"配置文件有四个部分\",{\"1\":{\"5\":1}}],[\"配置为\",{\"1\":{\"17\":3}}],[\"可用的生成组件\",{\"0\":{\"26\":1}}],[\"可用的存储组件\",{\"0\":{\"22\":1}}],[\"可用的\",{\"0\":{\"17\":1}}],[\"可以添加该方法\",{\"1\":{\"21\":1}}],[\"可以重写该方法\",{\"1\":{\"21\":3}}],[\"可以是\",{\"1\":{\"20\":1,\"24\":2}}],[\"可以实现\",{\"1\":{\"16\":1}}],[\"可以指定\",{\"1\":{\"15\":1}}],[\"可以快速部署\",{\"1\":{\"11\":1}}],[\"可以简化各种\",{\"1\":{\"11\":1}}],[\"可以通过docker镜像运行\",{\"1\":{\"10\":1}}],[\"可以通过pip快速安装\",{\"1\":{\"10\":1}}],[\"可以通过下面的代码来完成一个简单的\",{\"1\":{\"8\":1}}],[\"可以访问\",{\"1\":{\"7\":1}}],[\"可以前往xinference\",{\"1\":{\"7\":1}}],[\"可以使用\",{\"1\":{\"7\":1}}],[\">\",{\"1\":{\"16\":1,\"21\":5,\"25\":1}}],[\"方法默认不提供\",{\"1\":{\"21\":1}}],[\"方法默认调用\",{\"1\":{\"21\":3}}],[\"方法不关心这些方法的返回值\",{\"1\":{\"16\":1}}],[\"方法返回\",{\"1\":{\"16\":1}}],[\"方法传递所需的参数\",{\"1\":{\"16\":1}}],[\"方法\",{\"1\":{\"16\":3,\"21\":3}}],[\"方法时预加载模型\",{\"1\":{\"15\":1}}],[\"需要将召回结果与用户的问题结合生成\",{\"1\":{\"23\":1}}],[\"需要在\",{\"1\":{\"21\":1}}],[\"需要创建一个新的类\",{\"1\":{\"21\":1}}],[\"需要重写\",{\"1\":{\"16\":1}}],[\"需要继承\",{\"1\":{\"16\":1,\"25\":1}}],[\"需要安装依赖\",{\"1\":{\"3\":1}}],[\"要集成新的存储组件\",{\"1\":{\"21\":1}}],[\"要集成新的\",{\"1\":{\"16\":1}}],[\"如何添加新的生成组件\",{\"0\":{\"25\":1}}],[\"如何添加新的存储组件\",{\"0\":{\"21\":1}}],[\"如何添加新的\",{\"0\":{\"16\":1}}],[\"如果有更高效的实现方式\",{\"1\":{\"21\":3}}],[\"如果有多个\",{\"1\":{\"7\":1}}],[\"如果希望使用返回值\",{\"1\":{\"16\":1}}],[\"如果需要添加自定义的生成组件\",{\"1\":{\"25\":1}}],[\"如果需要一次搜索多个\",{\"1\":{\"21\":1}}],[\"如果需要预处理或后处理\",{\"1\":{\"16\":1}}],[\"如果需要使用\",{\"1\":{\"7\":1}}],[\"如果\",{\"1\":{\"15\":1}}],[\"如果你有任何问题或建议\",{\"1\":{\"13\":1}}],[\"如果你希望使用上面的配置搭建自己的\",{\"1\":{\"7\":1}}],[\"而模型名称用于加载模型\",{\"1\":{\"15\":1}}],[\"类负责根据配置创建存储组件\",{\"1\":{\"21\":1}}],[\"类中注册新的存储组件\",{\"1\":{\"21\":1}}],[\"类并实现抽象方法\",{\"1\":{\"21\":1}}],[\"类\",{\"1\":{\"16\":1,\"25\":2}}],[\"类名用于在代码中定位相应的类\",{\"1\":{\"15\":1}}],[\"类型\",{\"1\":{\"14\":1}}],[\"分隔为两部分\",{\"1\":{\"15\":1}}],[\"由\",{\"1\":{\"15\":1}}],[\"格式\",{\"1\":{\"15\":1,\"20\":1}}],[\"访问远程服务器的可选\",{\"1\":{\"15\":1}}],[\"例如\",{\"1\":{\"15\":1}}],[\"对于多个\",{\"1\":{\"15\":1}}],[\"或路径\",{\"1\":{\"29\":1}}],[\"或者继承\",{\"1\":{\"25\":1}}],[\"或者直接继承\",{\"1\":{\"16\":1}}],[\"或者也可以从\",{\"1\":{\"7\":1}}],[\"或\",{\"1\":{\"15\":1,\"16\":2,\"20\":1,\"24\":2}}],[\"那么远程服务器需要具有所指定的模型名称或者路径的访问权限\",{\"1\":{\"15\":1}}],[\"那么需要首先启动\",{\"1\":{\"7\":1}}],[\"被设置为\",{\"1\":{\"15\":1}}],[\"代码中\",{\"1\":{\"15\":1}}],[\"组件\",{\"1\":{\"14\":1}}],[\"中生成组件的配置\",{\"1\":{\"24\":1}}],[\"中存储组件的配置\",{\"1\":{\"20\":1}}],[\"中的\",{\"1\":{\"16\":1}}],[\"中\",{\"1\":{\"15\":1,\"18\":1,\"28\":1}}],[\"中使用\",{\"1\":{\"14\":1}}],[\"中最重要的组件之一\",{\"1\":{\"14\":1}}],[\"接下来\",{\"1\":{\"14\":1}}],[\"模型名称也分为两个部分\",{\"1\":{\"29\":1}}],[\"模型使用的引擎\",{\"1\":{\"28\":1}}],[\"模型\",{\"0\":{\"16\":1,\"17\":1},\"1\":{\"16\":1}}],[\"模型的量化属性\",{\"1\":{\"28\":1}}],[\"模型的大小\",{\"1\":{\"28\":1}}],[\"模型的格式\",{\"1\":{\"28\":1}}],[\"模型的操作和集成\",{\"1\":{\"27\":1}}],[\"模型的类名和模型名称\",{\"1\":{\"15\":1}}],[\"模型的名称或路径\",{\"1\":{\"15\":1}}],[\"模型的运行和集成\",{\"1\":{\"11\":1}}],[\"模型并不直接在本地机器上运行\",{\"1\":{\"14\":1}}],[\"容器加载模型\",{\"1\":{\"14\":1}}],[\"这一部分由\",{\"1\":{\"23\":1}}],[\"这种方法需要从远程服务器或\",{\"1\":{\"14\":1}}],[\"这种方法需要从本地文件系统加载模型\",{\"1\":{\"14\":1}}],[\"这些工作为我们框架的搭建提供了很大的帮助\",{\"1\":{\"11\":1}}],[\"提供了两种\",{\"1\":{\"14\":1}}],[\"提供了一种简单\",{\"1\":{\"9\":1}}],[\"并不由生成组件负责\",{\"1\":{\"23\":1}}],[\"并实现抽象方法\",{\"1\":{\"25\":1}}],[\"并实现\",{\"1\":{\"16\":1}}],[\"并将转换后的向量用于从数据库中检索相关信息\",{\"1\":{\"14\":1}}],[\"并且直接在本地机器上运行\",{\"1\":{\"14\":1}}],[\"并且在工厂中注册你的组件\",{\"1\":{\"10\":1}}],[\"并且主机的\",{\"1\":{\"7\":1}}],[\"它将输入文本转换为向量表示\",{\"1\":{\"14\":1}}],[\"是一个开源平台\",{\"1\":{\"27\":1}}],[\"是否在调用之前加载模型\",{\"1\":{\"24\":1}}],[\"是否在尚未调用\",{\"1\":{\"15\":1}}],[\"是否需要返回召回结果\",{\"1\":{\"8\":1}}],[\"是本地还是远程\",{\"1\":{\"15\":1}}],[\"是\",{\"1\":{\"14\":1}}],[\"请参阅\",{\"1\":{\"18\":1,\"27\":1}}],[\"请通过邮件或github\",{\"1\":{\"13\":1}}],[\"请查看贡献指南获取更多信息\",{\"1\":{\"12\":1}}],[\"联系我们\",{\"0\":{\"13\":1}}],[\"✉️\",{\"0\":{\"13\":1}}],[\"贡献代码\",{\"1\":{\"12\":1}}],[\"贡献\",{\"0\":{\"12\":1}}],[\"🤝\",{\"0\":{\"12\":1}}],[\"主题\",{\"1\":{\"11\":1}}],[\"一个开源的向量数据库\",{\"1\":{\"11\":1}}],[\"一个具有强大功能的\",{\"1\":{\"11\":1}}],[\"一个简单的静态网站搭建框架\",{\"1\":{\"11\":1}}],[\"value\",{\"1\":{\"16\":2}}],[\"vuepress\",{\"1\":{\"11\":3}}],[\"version\",{\"1\":{\"2\":1,\"3\":1}}],[\"排名不分先后\",{\"1\":{\"11\":1}}],[\"致谢\",{\"0\":{\"11\":1}}],[\"🙏\",{\"0\":{\"11\":1}}],[\"就考虑到了异步操作\",{\"1\":{\"10\":1}}],[\"就可以在配置文件中使用你的组件了\",{\"1\":{\"10\":1}}],[\"完全支持异步操作\",{\"1\":{\"10\":1}}],[\"特性\",{\"0\":{\"10\":1}}],[\"🌟\",{\"0\":{\"10\":1}}],[\"任务的流程的框架\",{\"1\":{\"9\":1}}],[\"高度可自定义\",{\"1\":{\"9\":1,\"10\":1}}],[\"简介\",{\"0\":{\"9\":1,\"23\":1}}],[\"format\",{\"1\":{\"28\":2}}],[\"float\",{\"1\":{\"16\":1,\"21\":3}}],[\"false\",{\"1\":{\"15\":1,\"24\":1}}],[\"f\",{\"1\":{\"8\":2}}],[\"from\",{\"1\":{\"8\":4}}],[\"召回的文档数量\",{\"1\":{\"8\":1}}],[\"k\",{\"1\":{\"8\":2,\"21\":1}}],[\"问题\",{\"1\":{\"8\":1}}],[\"what\",{\"1\":{\"8\":1}}],[\"websearch\",{\"1\":{\"5\":1}}],[\"your\",{\"1\":{\"8\":2}}],[\"=\",{\"1\":{\"8\":8,\"15\":5,\"16\":3,\"20\":4,\"21\":3,\"24\":6,\"25\":2,\"28\":3}}],[\"在配置文件中\",{\"1\":{\"20\":1}}],[\"在配置文件\",{\"1\":{\"15\":1}}],[\"在设计之初\",{\"1\":{\"10\":1}}],[\"在启动\",{\"1\":{\"7\":1}}],[\"在这个例子中\",{\"1\":{\"7\":1}}],[\"在这一部分\",{\"1\":{\"5\":1,\"18\":1}}],[\"版本\",{\"1\":{\"7\":1}}],[\"版本必须大于等于\",{\"1\":{\"7\":1}}],[\"的示例\",{\"1\":{\"16\":1}}],[\"的设置如下\",{\"1\":{\"15\":1}}],[\"的机器上运行\",{\"1\":{\"7\":1}}],[\"的配置\",{\"1\":{\"5\":1,\"15\":1}}],[\"上述镜像只能在有\",{\"1\":{\"7\":1}}],[\"来检查服务是否正常运行\",{\"1\":{\"7\":1}}],[\"来制定所需要使用的\",{\"1\":{\"7\":1}}],[\"来启动\",{\"1\":{\"7\":1}}],[\"2\",{\"1\":{\"7\":1}}],[\"参数必须设置\",{\"1\":{\"7\":1}}],[\"data\",{\"1\":{\"20\":1}}],[\"database\",{\"1\":{\"19\":1}}],[\"disk\",{\"1\":{\"19\":1}}],[\"directly\",{\"1\":{\"19\":1}}],[\"dict\",{\"1\":{\"16\":2}}],[\"delete\",{\"1\":{\"21\":4}}],[\"device\",{\"1\":{\"15\":2,\"24\":2}}],[\"default\",{\"1\":{\"8\":1}}],[\"def\",{\"1\":{\"8\":1,\"16\":1,\"21\":5,\"25\":1}}],[\"debug\",{\"1\":{\"7\":1}}],[\"docs\",{\"1\":{\"8\":8,\"16\":2}}],[\"document\",{\"1\":{\"8\":1,\"16\":1,\"21\":14}}],[\"documents\",{\"1\":{\"8\":3,\"19\":2,\"21\":2}}],[\"docker\",{\"0\":{\"4\":1},\"1\":{\"4\":1,\"7\":5,\"14\":1,\"19\":1}}],[\"0\",{\"1\":{\"7\":5,\"15\":1}}],[\"驱动和\",{\"1\":{\"7\":1}}],[\"拉取镜像\",{\"1\":{\"7\":1}}],[\"list\",{\"1\":{\"16\":3,\"21\":4,\"25\":1}}],[\"literal\",{\"1\":{\"15\":1,\"20\":1,\"24\":1,\"25\":1}}],[\"llm\",{\"1\":{\"11\":1}}],[\"level\",{\"1\":{\"7\":1}}],[\"load\",{\"1\":{\"8\":1}}],[\"loader\",{\"1\":{\"8\":3}}],[\"log\",{\"1\":{\"7\":1}}],[\"localgenerator\",{\"1\":{\"25\":1}}],[\"localembeddinggetter\",{\"1\":{\"16\":1}}],[\"local\",{\"1\":{\"6\":2,\"7\":1,\"14\":1,\"15\":1,\"17\":1,\"19\":2,\"20\":7,\"22\":1,\"24\":2,\"26\":1}}],[\"localhost\",{\"1\":{\"6\":2,\"7\":1,\"15\":1,\"29\":1}}],[\"latest\",{\"1\":{\"7\":3}}],[\"xorbits\",{\"1\":{\"27\":1}}],[\"xinferncegenerator\",{\"1\":{\"26\":1}}],[\"xinferenceconfig\",{\"1\":{\"24\":1,\"28\":1}}],[\"xinferenceembeddinggetter\",{\"1\":{\"17\":1}}],[\"xinference\",{\"0\":{\"7\":1,\"27\":1},\"1\":{\"6\":5,\"7\":11,\"11\":1,\"15\":1,\"17\":1,\"24\":4,\"26\":2,\"27\":2,\"28\":11,\"29\":4}}],[\"xxx\",{\"1\":{\"26\":3}}],[\"xprobe\",{\"1\":{\"7\":3}}],[\"auto\",{\"1\":{\"28\":1}}],[\"assistant\",{\"1\":{\"25\":1}}],[\"async\",{\"1\":{\"8\":1,\"16\":1,\"21\":5,\"25\":1}}],[\"asyncio\",{\"1\":{\"8\":2}}],[\"a\",{\"1\":{\"19\":2}}],[\"api\",{\"1\":{\"18\":1}}],[\"after\",{\"1\":{\"16\":3}}],[\"any\",{\"1\":{\"16\":2}}],[\"and\",{\"1\":{\"8\":1,\"19\":2}}],[\"args=\",{\"1\":{\"16\":2}}],[\"args\",{\"1\":{\"16\":4}}],[\"ai\",{\"1\":{\"11\":1,\"27\":1}}],[\"add\",{\"1\":{\"8\":1,\"21\":5}}],[\"await\",{\"1\":{\"8\":3,\"16\":1}}],[\"all\",{\"1\":{\"7\":1}}],[\"aliyuncs\",{\"1\":{\"7\":1}}],[\"activate\",{\"1\":{\"2\":1}}],[\"history\",{\"1\":{\"25\":1}}],[\"hope\",{\"1\":{\"11\":1}}],[\"h\",{\"1\":{\"7\":2}}],[\"hub\",{\"1\":{\"7\":1}}],[\"hangzhou\",{\"1\":{\"7\":1}}],[\"http\",{\"1\":{\"6\":2,\"7\":1,\"15\":1,\"29\":1}}],[\"https\",{\"1\":{\"3\":1}}],[\"国内用户可以使用下面的命令从阿里云拉取镜像\",{\"1\":{\"7\":1}}],[\"文档\",{\"1\":{\"18\":1,\"27\":1}}],[\"文档获取更多信息\",{\"1\":{\"7\":1}}],[\"文档来获取更多信息\",{\"1\":{\"7\":1}}],[\"文件来进行整个\",{\"1\":{\"5\":1}}],[\"服务进行生成的生成器\",{\"1\":{\"26\":2}}],[\"服务时需要\",{\"1\":{\"24\":1}}],[\"服务的配置\",{\"1\":{\"24\":1,\"28\":1}}],[\"服务之后\",{\"1\":{\"7\":1}}],[\"服务\",{\"0\":{\"7\":1},\"1\":{\"7\":3}}],[\"by\",{\"1\":{\"21\":11}}],[\"bert\",{\"1\":{\"17\":1}}],[\"bertembeddinggetter\",{\"1\":{\"17\":1}}],[\"bool\",{\"1\":{\"15\":1,\"24\":1}}],[\"basemodel\",{\"1\":{\"15\":1,\"20\":1,\"24\":1,\"28\":1}}],[\"bit\",{\"1\":{\"6\":1,\"29\":1}}],[\"bge\",{\"1\":{\"6\":1,\"15\":1}}],[\"4\",{\"1\":{\"6\":1,\"7\":1,\"29\":1}}],[\"query\",{\"1\":{\"8\":2}}],[\"quantization\",{\"1\":{\"6\":1,\"28\":2,\"29\":1}}],[\"qwen2\",{\"1\":{\"6\":1,\"29\":1}}],[\"5\",{\"1\":{\"6\":1,\"8\":1,\"21\":1,\"29\":1}}],[\"system\",{\"1\":{\"25\":3}}],[\"search\",{\"1\":{\"21\":3}}],[\"sentence\",{\"1\":{\"17\":1}}],[\"sentencetransformerembeddinggetter\",{\"1\":{\"17\":1}}],[\"self\",{\"1\":{\"8\":1,\"16\":1,\"21\":5,\"25\":1}}],[\"str\",{\"1\":{\"15\":4,\"16\":2,\"20\":4,\"21\":9,\"24\":4,\"25\":4,\"28\":5}}],[\"storefactory\",{\"1\":{\"21\":2}}],[\"storeconfig\",{\"1\":{\"20\":1}}],[\"store\",{\"1\":{\"5\":1,\"6\":4,\"19\":2,\"20\":17,\"21\":1}}],[\"split\",{\"1\":{\"8\":1}}],[\"splitter=charactersplitter\",{\"1\":{\"8\":1}}],[\"splitter\",{\"1\":{\"8\":1}}],[\"src=modelscope\",{\"1\":{\"7\":1}}],[\"size\",{\"1\":{\"6\":1,\"28\":2,\"29\":1}}],[\"9997\",{\"1\":{\"6\":2,\"7\":3,\"15\":1,\"29\":1}}],[\"main\",{\"1\":{\"8\":2}}],[\"mdoel\",{\"1\":{\"6\":1,\"28\":2,\"29\":1}}],[\"m3\",{\"1\":{\"6\":1,\"15\":1}}],[\"model\",{\"1\":{\"6\":4,\"7\":1,\"15\":9,\"17\":3,\"24\":6,\"26\":3,\"28\":6,\"29\":2}}],[\"optional\",{\"1\":{\"15\":3,\"20\":4,\"24\":4}}],[\"ops\",{\"1\":{\"3\":1}}],[\"ollamagenerator\",{\"1\":{\"26\":1}}],[\"ollama\",{\"1\":{\"11\":1,\"26\":2}}],[\"of\",{\"1\":{\"8\":1}}],[\"or\",{\"1\":{\"6\":2,\"15\":4,\"17\":3,\"19\":1,\"24\":2,\"26\":3,\"29\":1}}],[\"基本配置\",{\"0\":{\"6\":1,\"15\":1,\"20\":1,\"24\":1,\"28\":1}}],[\"重排序\",{\"1\":{\"5\":1}}],[\"预计未来最少会加入两个模块\",{\"1\":{\"5\":1}}],[\"部分可以选择不配置\",{\"1\":{\"5\":1}}],[\"其中\",{\"1\":{\"5\":1}}],[\"和网络搜索\",{\"1\":{\"5\":1}}],[\"和\",{\"1\":{\"5\":1,\"7\":1,\"16\":1}}],[\"目前\",{\"1\":{\"5\":1}}],[\"目前只支持从源码安装\",{\"1\":{\"1\":1}}],[\"json\",{\"1\":{\"5\":1,\"8\":1,\"15\":1,\"20\":1}}],[\"使用的\",{\"1\":{\"28\":1}}],[\"使用换行符分割文档\",{\"1\":{\"8\":1}}],[\"使用\",{\"1\":{\"5\":1,\"26\":1}}],[\"我们会尽快回复你\",{\"1\":{\"13\":1}}],[\"我们欢迎更多开发者为\",{\"1\":{\"12\":1}}],[\"我们十分感谢前任所做的工作\",{\"1\":{\"11\":1}}],[\"我们可以使用这条命令来启动\",{\"1\":{\"7\":1}}],[\"我们需要确认已经安装了\",{\"1\":{\"7\":1}}],[\"我们需要拉取\",{\"1\":{\"7\":1}}],[\"我们将介绍如何使用\",{\"1\":{\"18\":1}}],[\"我们将介绍如何在\",{\"1\":{\"14\":1}}],[\"我们将介绍如何搭建一个基本的\",{\"1\":{\"5\":1}}],[\"我们将使用\",{\"1\":{\"7\":1}}],[\"我们将使用这个配置文件来搭建一个简单的\",{\"1\":{\"6\":1}}],[\"我们也提供了一个\",{\"1\":{\"4\":1}}],[\"快速入门\",{\"0\":{\"5\":1}}],[\"开发中\",{\"1\":{\"4\":1,\"10\":2}}],[\"镜像\",{\"1\":{\"4\":1,\"7\":1}}],[\"engine\",{\"1\":{\"28\":2}}],[\"embeddings\",{\"1\":{\"19\":2,\"21\":1}}],[\"embeddinggetter\",{\"1\":{\"16\":1}}],[\"embeddingconfig\",{\"1\":{\"15\":1}}],[\"embedding\",{\"0\":{\"14\":1,\"16\":1,\"17\":1},\"1\":{\"5\":1,\"6\":5,\"14\":3,\"15\":28,\"16\":15,\"19\":3,\"21\":9}}],[\"e\",{\"1\":{\"3\":1,\"7\":1}}],[\"直接安装\",{\"1\":{\"3\":1}}],[\"最后\",{\"1\":{\"3\":1,\"7\":1}}],[\"最简单的方法是通过\",{\"1\":{\"2\":1}}],[\"transformers\",{\"1\":{\"26\":2,\"28\":1}}],[\"transformersgenerator\",{\"1\":{\"26\":1}}],[\"transformer\",{\"1\":{\"17\":1}}],[\"true\",{\"1\":{\"6\":1,\"8\":1,\"15\":1}}],[\"theme\",{\"1\":{\"11\":1}}],[\"the\",{\"1\":{\"8\":1,\"19\":2}}],[\"token\",{\"1\":{\"15\":3,\"20\":4,\"24\":4}}],[\"top\",{\"1\":{\"8\":2,\"21\":1}}],[\"toolkit的文档可以在这里找到\",{\"1\":{\"7\":1}}],[\"toolkit\",{\"1\":{\"7\":1}}],[\"to\",{\"1\":{\"6\":1,\"8\":2,\"20\":1}}],[\"torchaudio\",{\"1\":{\"2\":1}}],[\"torchvision\",{\"1\":{\"2\":1}}],[\"torch\",{\"1\":{\"2\":1}}],[\"typeddict\",{\"1\":{\"25\":1}}],[\"type\",{\"1\":{\"6\":3,\"15\":4,\"20\":6,\"24\":5,\"29\":1}}],[\"txt\",{\"1\":{\"3\":1}}],[\"之后\",{\"1\":{\"3\":1,\"7\":1}}],[\"generate\",{\"1\":{\"25\":2}}],[\"generator\",{\"1\":{\"23\":1,\"25\":1}}],[\"generationconfig\",{\"1\":{\"24\":1}}],[\"generation\",{\"1\":{\"5\":1,\"6\":5,\"24\":17,\"29\":5}}],[\"getter\",{\"1\":{\"16\":1}}],[\"get\",{\"1\":{\"8\":1,\"15\":1,\"16\":6,\"21\":4}}],[\"gpu\",{\"1\":{\"7\":3,\"15\":2,\"24\":1,\"28\":1}}],[\"gpus\",{\"1\":{\"7\":3}}],[\"github\",{\"1\":{\"3\":1}}],[\"git\",{\"1\":{\"3\":2}}],[\"guide\",{\"0\":{\"1\":1}}],[\"inference\",{\"1\":{\"27\":1}}],[\"int\",{\"1\":{\"21\":1}}],[\"in\",{\"1\":{\"19\":2}}],[\"instruct\",{\"1\":{\"6\":1,\"29\":1}}],[\"install\",{\"1\":{\"2\":2,\"3\":2}}],[\"installation\",{\"0\":{\"1\":1}}],[\"ids\",{\"1\":{\"21\":2}}],[\"id\",{\"1\":{\"15\":1,\"21\":11}}],[\"issues联系我们\",{\"1\":{\"13\":1}}],[\"is\",{\"1\":{\"8\":1}}],[\"import\",{\"1\":{\"2\":1,\"3\":1,\"8\":5}}],[\"然后\",{\"1\":{\"2\":1}}],[\"1\",{\"1\":{\"2\":1,\"6\":1,\"7\":1,\"29\":1}}],[\"12\",{\"1\":{\"2\":1,\"7\":1}}],[\"10\",{\"1\":{\"2\":1}}],[\"role\",{\"1\":{\"25\":1}}],[\"run\",{\"1\":{\"7\":1,\"8\":1}}],[\"responsemessage\",{\"1\":{\"25\":3}}],[\"response\",{\"1\":{\"8\":4}}],[\"related\",{\"1\":{\"8\":5}}],[\"return\",{\"1\":{\"8\":2}}],[\"registry\",{\"1\":{\"7\":1}}],[\"registerrag\",{\"1\":{\"3\":2}}],[\"register\",{\"1\":{\"2\":5,\"3\":4,\"5\":2,\"8\":4,\"9\":1,\"10\":1,\"12\":1,\"14\":3,\"16\":1,\"18\":1}}],[\"remotegenerator\",{\"1\":{\"25\":1}}],[\"remoteembeddinggetter\",{\"1\":{\"16\":1}}],[\"remote\",{\"1\":{\"6\":4,\"14\":1,\"15\":8,\"17\":1,\"19\":2,\"20\":8,\"24\":9,\"26\":1,\"29\":2}}],[\"rerank\",{\"1\":{\"5\":1}}],[\"requirements\",{\"1\":{\"3\":1}}],[\"r\",{\"1\":{\"3\":1}}],[\"rag\",{\"1\":{\"2\":5,\"3\":4,\"5\":2,\"6\":1,\"7\":1,\"8\":5,\"9\":2,\"10\":1,\"12\":1,\"14\":3,\"16\":1,\"18\":2}}],[\"ngpu\",{\"1\":{\"28\":2}}],[\"none\",{\"1\":{\"15\":3,\"16\":3,\"20\":4,\"21\":5,\"24\":4,\"25\":2}}],[\"note\",{\"1\":{\"1\":1,\"7\":1,\"16\":1,\"29\":1}}],[\"nvidia\",{\"1\":{\"7\":3}}],[\"name\",{\"1\":{\"6\":3,\"8\":3,\"15\":4,\"17\":3,\"20\":3,\"21\":5,\"24\":2,\"26\":3,\"29\":1}}],[\"n\",{\"1\":{\"2\":1}}],[\"class\",{\"1\":{\"15\":1,\"20\":1,\"24\":1,\"25\":1,\"28\":1}}],[\"clone\",{\"1\":{\"3\":1}}],[\"capital\",{\"1\":{\"8\":1}}],[\"cpu\",{\"1\":{\"7\":1,\"15\":2,\"24\":2}}],[\"cn\",{\"1\":{\"7\":1}}],[\"china\",{\"1\":{\"8\":1}}],[\"charactersplitter\",{\"1\":{\"8\":1}}],[\"charon\",{\"1\":{\"3\":1}}],[\"chromastore\",{\"1\":{\"22\":1}}],[\"chroma\",{\"1\":{\"6\":2,\"11\":1,\"20\":1,\"22\":1}}],[\"cd\",{\"1\":{\"3\":1}}],[\"collection\",{\"1\":{\"8\":3,\"21\":5}}],[\"content\",{\"1\":{\"25\":1}}],[\"container\",{\"1\":{\"7\":2,\"19\":1}}],[\"configuration\",{\"1\":{\"8\":1}}],[\"config\",{\"1\":{\"6\":1,\"24\":2,\"29\":1}}],[\"conda\",{\"1\":{\"2\":2}}],[\"com\",{\"1\":{\"3\":1,\"7\":1}}],[\"c\",{\"1\":{\"2\":1,\"3\":1}}],[\"cuda\",{\"1\":{\"2\":1,\"7\":1,\"15\":2,\"24\":1}}],[\"create\",{\"1\":{\"2\":1}}],[\"你只需要继承基类\",{\"1\":{\"10\":1}}],[\"你也可以简单地添加自己的组件\",{\"1\":{\"10\":1}}],[\"你也可以从源码安装\",{\"1\":{\"3\":1}}],[\"你需要克隆仓库\",{\"1\":{\"3\":1}}],[\"你需要安装\",{\"1\":{\"2\":1}}],[\"你可以轻松地并行运行多个组件\",{\"1\":{\"10\":1}}],[\"你可以使用我们提供的组件快速搭建自己的\",{\"1\":{\"18\":1}}],[\"你可以使用我们提供的组件\",{\"1\":{\"10\":1}}],[\"你可以访问xinference\",{\"1\":{\"7\":1}}],[\"你可以通过以下命令拉取镜像\",{\"1\":{\"4\":1}}],[\"你可以运行以下命令来检查安装是否成功\",{\"1\":{\"2\":1,\"3\":1}}],[\"你可以在这里找到安装方法\",{\"1\":{\"2\":1}}],[\"post\",{\"1\":{\"16\":2}}],[\"pdf\",{\"1\":{\"8\":1}}],[\"pdfloader\",{\"1\":{\"8\":2}}],[\"p\",{\"1\":{\"7\":1}}],[\"pull\",{\"1\":{\"7\":2}}],[\"path\",{\"1\":{\"6\":4,\"8\":2,\"15\":4,\"17\":3,\"20\":4,\"24\":2,\"26\":3,\"29\":1}}],[\"pre\",{\"1\":{\"16\":5}}],[\"preload\",{\"1\":{\"6\":1,\"15\":3,\"24\":2}}],[\"promptgenerator\",{\"1\":{\"23\":2}}],[\"prompt\",{\"1\":{\"5\":2,\"23\":3,\"25\":4}}],[\"print\",{\"1\":{\"2\":1,\"3\":1,\"8\":2}}],[\"python\",{\"1\":{\"2\":1,\"3\":1,\"15\":1,\"20\":1,\"24\":1,\"28\":1}}],[\"python==3\",{\"1\":{\"2\":1}}],[\"pytorch\",{\"1\":{\"2\":1,\"28\":1}}],[\"pipeline\",{\"0\":{\"8\":1},\"1\":{\"5\":2,\"6\":1,\"7\":1,\"8\":6,\"18\":3}}],[\"pip3\",{\"1\":{\"2\":2}}],[\"pip\",{\"0\":{\"2\":1},\"1\":{\"2\":1,\"3\":2}}],[\"首先\",{\"1\":{\"2\":1,\"3\":1,\"7\":1}}],[\"安装简便\",{\"1\":{\"10\":1}}],[\"安装\",{\"0\":{\"2\":1}}],[\"通过修改配置文件搭建自己的框架\",{\"1\":{\"10\":1}}],[\"通过\",{\"0\":{\"2\":1},\"1\":{\"16\":1}}]],\"serializationVersion\":2}}")).map(([e,t])=>[e,zt(t,{fields:["h","t","c"],storeFields:["h","t","c"]})]));self.onmessage=({data:{type:e="all",query:t,locale:s,options:n,id:o}})=>{const u=bt[s];e==="suggest"?self.postMessage([e,o,tt(t,u,n)]):e==="search"?self.postMessage([e,o,Z(t,u,n)]):self.postMessage({suggestions:[e,o,tt(t,u,n)],results:[e,o,Z(t,u,n)]})};
//# sourceMappingURL=index.js.map
